{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Growing Neural Cellular Automata",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28S76DVlfCMZ"
      },
      "source": [
        "# Growing Neural Cellular Automata\n",
        "\n",
        "This notebook contains code to reproduce experiments and figures for the [\"Growing Neural Cellular Automata\"](http://distill.pub/2020/growing-ca) article.\n",
        "\n",
        "Copyright 2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5wi_r4gyzFr"
      },
      "source": [
        "#@title Imports and Notebook Utilities\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "clear_output()\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def imshow(a, fmt='jpeg'):\n",
        "  display(Image(data=imencode(a, fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(len(a))))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w-len(a))%w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = len(a)//w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename, fps=30.0, **kw):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kw)\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in [np.float32, np.float64]:\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if len(img.shape) == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer:\n",
        "      self.writer.close()\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *kw):\n",
        "    self.close()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR6I1JONmWBb"
      },
      "source": [
        "#@title Cellular Automata Parameters\n",
        "CHANNEL_N = 16        # Number of CA state channels\n",
        "TARGET_PADDING = 16   # Number of pixels used to pad the target image border\n",
        "TARGET_SIZE = 40\n",
        "BATCH_SIZE = 8\n",
        "POOL_SIZE = 1024\n",
        "CELL_FIRE_RATE = 0.5\n",
        "\n",
        "TARGET_EMOJI = \"ü¶é\" #@param {type:\"string\"}\n",
        "\n",
        "EXPERIMENT_TYPE = \"Regenerating\" #@param [\"Growing\", \"Persistent\", \"Regenerating\"]\n",
        "EXPERIMENT_MAP = {\"Growing\":0, \"Persistent\":1, \"Regenerating\":2}\n",
        "EXPERIMENT_N = EXPERIMENT_MAP[EXPERIMENT_TYPE]\n",
        "\n",
        "USE_PATTERN_POOL = [0, 1, 1][EXPERIMENT_N]\n",
        "DAMAGE_N = [0, 0, 3][EXPERIMENT_N]  # Number of patterns to damage in a batch"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCbPFbI_zosW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "6c7ea704-78fe-4bfa-b5d5-4c800f8f0df5"
      },
      "source": [
        "#@title CA Model and Utilities\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "def load_image(url, max_size=TARGET_SIZE):\n",
        "  r = requests.get(url)\n",
        "  img = PIL.Image.open(io.BytesIO(r.content))\n",
        "  img.thumbnail((max_size, max_size), PIL.Image.LANCZOS)\n",
        "  img = np.float32(img)/255.0\n",
        "  # premultiply RGB by Alpha\n",
        "  img[..., :3] *= img[..., 3:]\n",
        "  return img\n",
        "\n",
        "def load_emoji(emoji):\n",
        "  code = hex(ord(emoji))[2:].lower()\n",
        "  url = 'https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
        "  return load_image(url)\n",
        "\n",
        "\n",
        "def to_rgba(x):\n",
        "  return x[..., :4]\n",
        "\n",
        "def to_alpha(x):\n",
        "  return tf.clip_by_value(x[..., 3:4], 0.0, 1.0)\n",
        "\n",
        "def to_rgb(x):\n",
        "  # assume rgb premultiplied by alpha\n",
        "  rgb, a = x[..., :3], to_alpha(x)\n",
        "  return 1.0-a+rgb\n",
        "\n",
        "def get_living_mask(x):\n",
        "  alpha = x[:, :, :, 3:4]\n",
        "  return tf.nn.max_pool2d(alpha, 3, [1, 1, 1, 1], 'SAME') > 0.1\n",
        "\n",
        "def make_seed(size, n=1):\n",
        "  x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
        "  x[:, size//2, size//2, 3:] = 1.0\n",
        "  return x\n",
        "\n",
        "\n",
        "class CAModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
        "    super().__init__()\n",
        "    self.channel_n = channel_n\n",
        "    self.fire_rate = fire_rate\n",
        "\n",
        "    self.dmodel = tf.keras.Sequential([\n",
        "          Conv2D(128, 1, activation=tf.nn.relu),\n",
        "          Conv2D(self.channel_n, 1, activation=None,\n",
        "              kernel_initializer=tf.zeros_initializer),\n",
        "    ])\n",
        "\n",
        "    self(tf.zeros([1, 3, 3, channel_n]))  # dummy call to build the model\n",
        "\n",
        "  @tf.function\n",
        "  def perceive(self, x, angle=0.0):\n",
        "    identify = np.float32([0, 1, 0])\n",
        "    identify = np.outer(identify, identify)\n",
        "    dx = np.outer([1, 2, 1], [-1, 0, 1]) / 8.0  # Sobel filter\n",
        "    dy = dx.T\n",
        "    c, s = tf.cos(angle), tf.sin(angle)\n",
        "    kernel = tf.stack([identify, c*dx-s*dy, s*dx+c*dy], -1)[:, :, None, :]\n",
        "    kernel = tf.repeat(kernel, self.channel_n, 2)\n",
        "    y = tf.nn.depthwise_conv2d(x, kernel, [1, 1, 1, 1], 'SAME')\n",
        "    return y\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
        "    pre_life_mask = get_living_mask(x)\n",
        "\n",
        "    y = self.perceive(x, angle)\n",
        "    dx = self.dmodel(y)*step_size\n",
        "    if fire_rate is None:\n",
        "      fire_rate = self.fire_rate\n",
        "    update_mask = tf.random.uniform(tf.shape(x[:, :, :, :1])) <= fire_rate\n",
        "    x += dx * tf.cast(update_mask, tf.float32)\n",
        "\n",
        "    post_life_mask = get_living_mask(x)\n",
        "    life_mask = pre_life_mask & post_life_mask\n",
        "    return x * tf.cast(life_mask, tf.float32)\n",
        "\n",
        "\n",
        "CAModel().dmodel.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         ‚îÇ         \u001b[38;5;34m6,272\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          ‚îÇ         \u001b[38;5;34m2,064\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,336\u001b[0m (32.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,336</span> (32.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,336\u001b[0m (32.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,336</span> (32.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDX5HL7VLd0z"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeWf6HeTe8kM"
      },
      "source": [
        "#@title Train Utilities (SamplePool, Model Export, Damage)\n",
        "from google.protobuf.json_format import MessageToDict\n",
        "from tensorflow.python.framework import convert_to_constants\n",
        "\n",
        "class SamplePool:\n",
        "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
        "    self._parent = _parent\n",
        "    self._parent_idx = _parent_idx\n",
        "    self._slot_names = slots.keys()\n",
        "    self._size = None\n",
        "    for k, v in slots.items():\n",
        "      if self._size is None:\n",
        "        self._size = len(v)\n",
        "      assert self._size == len(v)\n",
        "      setattr(self, k, np.asarray(v))\n",
        "\n",
        "  def sample(self, n):\n",
        "    idx = np.random.choice(self._size, n, False)\n",
        "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
        "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
        "    return batch\n",
        "\n",
        "  def commit(self):\n",
        "    for k in self._slot_names:\n",
        "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
        "\n",
        "@tf.function\n",
        "def make_circle_masks(n, h, w):\n",
        "  x = tf.linspace(-1.0, 1.0, w)[None, None, :]\n",
        "  y = tf.linspace(-1.0, 1.0, h)[None, :, None]\n",
        "  center = tf.random.uniform([2, n, 1, 1], -0.5, 0.5)\n",
        "  r = tf.random.uniform([n, 1, 1], 0.1, 0.4)\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = tf.cast(x*x+y*y < 1.0, tf.float32)\n",
        "  return mask\n",
        "\n",
        "def export_model(ca, base_fn):\n",
        "  ca.save_weights(base_fn)\n",
        "\n",
        "  cf = ca.call.get_concrete_function(\n",
        "      x=tf.TensorSpec([None, None, None, CHANNEL_N]),\n",
        "      fire_rate=tf.constant(0.5),\n",
        "      angle=tf.constant(0.0),\n",
        "      step_size=tf.constant(1.0))\n",
        "  cf = convert_to_constants.convert_variables_to_constants_v2(cf)\n",
        "  graph_def = cf.graph.as_graph_def()\n",
        "  graph_json = MessageToDict(graph_def)\n",
        "  graph_json['versions'] = dict(producer='1.14', minConsumer='1.14')\n",
        "  model_json = {\n",
        "      'format': 'graph-model',\n",
        "      'modelTopology': graph_json,\n",
        "      'weightsManifest': [],\n",
        "  }\n",
        "  with open(base_fn+'.json', 'w') as f:\n",
        "    json.dump(model_json, f)\n",
        "\n",
        "def generate_pool_figures(pool, step_i):\n",
        "  tiled_pool = tile2d(to_rgb(pool.x[:49]))\n",
        "  fade = np.linspace(1.0, 0.0, 72)\n",
        "  ones = np.ones(72)\n",
        "  tiled_pool[:, :72] += (-tiled_pool[:, :72] + ones[None, :, None]) * fade[None, :, None]\n",
        "  tiled_pool[:, -72:] += (-tiled_pool[:, -72:] + ones[None, :, None]) * fade[None, ::-1, None]\n",
        "  tiled_pool[:72, :] += (-tiled_pool[:72, :] + ones[:, None, None]) * fade[:, None, None]\n",
        "  tiled_pool[-72:, :] += (-tiled_pool[-72:, :] + ones[:, None, None]) * fade[::-1, None, None]\n",
        "  imwrite('train_log/%04d_pool.jpg'%step_i, tiled_pool)\n",
        "\n",
        "def visualize_batch(x0, x, step_i):\n",
        "  vis0 = np.hstack(to_rgb(x0).numpy())\n",
        "  vis1 = np.hstack(to_rgb(x).numpy())\n",
        "  vis = np.vstack([vis0, vis1])\n",
        "  imwrite('train_log/batches_%04d.jpg'%step_i, vis)\n",
        "  print('batch (before/after):')\n",
        "  imshow(vis)\n",
        "\n",
        "def plot_loss(loss_log):\n",
        "  pl.figure(figsize=(10, 4))\n",
        "  pl.title('Loss history (log10)')\n",
        "  pl.plot(np.log10(loss_log), '.', alpha=0.1)\n",
        "  pl.show()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKlA50h0jlvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "6e28ae4a-1817-4870-8a4c-dd7929ddf6d5"
      },
      "source": [
        "#@title Choose Target Image { vertical-output: true}\n",
        "#url = 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/planaria2_48.png?raw=true'\n",
        "#target_img = load_image(url, 48)\n",
        "\n",
        "target_img = load_emoji(TARGET_EMOJI)\n",
        "imshow(zoom(to_rgb(target_img), 2), fmt='png')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak5rBmbxmHV7"
      },
      "source": [
        "#@title Initialize Training { vertical-output: true}\n",
        "\n",
        "p = TARGET_PADDING\n",
        "pad_target = tf.pad(target_img, [(p, p), (p, p), (0, 0)])\n",
        "h, w = pad_target.shape[:2]\n",
        "seed = np.zeros([h, w, CHANNEL_N], np.float32)\n",
        "seed[h//2, w//2, 3:] = 1.0\n",
        "\n",
        "def loss_f(x):\n",
        "  return tf.reduce_mean(tf.square(to_rgba(x)-pad_target), [-2, -3, -1])\n",
        "\n",
        "ca = CAModel()\n",
        "\n",
        "loss_log = []\n",
        "\n",
        "lr = 2e-3\n",
        "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    [2000], [lr, lr*0.1])\n",
        "trainer = tf.keras.optimizers.Adam(lr_sched)\n",
        "\n",
        "loss0 = loss_f(seed).numpy()\n",
        "pool = SamplePool(x=np.repeat(seed[None, ...], POOL_SIZE, 0))\n",
        "\n",
        "!mkdir -p train_log && rm -f train_log/*"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzP_vDchq0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "077b2109-0298-475c-d7f7-74c1fe26894e"
      },
      "source": [
        "#@title Training Loop {vertical-output: true}\n",
        "\n",
        "@tf.function\n",
        "def train_step(x):\n",
        "  iter_n = tf.random.uniform([], 64, 96, tf.int32)\n",
        "  with tf.GradientTape() as g:\n",
        "    for i in tf.range(iter_n):\n",
        "      x = ca(x)\n",
        "    loss = tf.reduce_mean(loss_f(x))\n",
        "  grads = g.gradient(loss, ca.weights)\n",
        "  grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
        "  trainer.apply_gradients(zip(grads, ca.weights))\n",
        "  return x, loss\n",
        "\n",
        "for i in range(8000+1):\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch = pool.sample(BATCH_SIZE)\n",
        "    x0 = batch.x\n",
        "    loss_rank = loss_f(x0).numpy().argsort()[::-1]\n",
        "    x0 = x0[loss_rank]\n",
        "    x0[:1] = seed\n",
        "    if DAMAGE_N:\n",
        "      damage = 1.0-make_circle_masks(DAMAGE_N, h, w).numpy()[..., None]\n",
        "      x0[-DAMAGE_N:] *= damage\n",
        "  else:\n",
        "    x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
        "\n",
        "  x, loss = train_step(x0)\n",
        "\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch.x[:] = x\n",
        "    batch.commit()\n",
        "\n",
        "  step_i = len(loss_log)\n",
        "  loss_log.append(loss.numpy())\n",
        "\n",
        "  if step_i%10 == 0:\n",
        "    generate_pool_figures(pool, step_i)\n",
        "  if step_i%100 == 0:\n",
        "    clear_output()\n",
        "    visualize_batch(x0, x, step_i)\n",
        "    plot_loss(loss_log)\n",
        "    export_model(ca, 'train_log/%04d.weights.h5'%step_i)\n",
        "\n",
        "  print('\\r step: %d, log10(loss): %.3f'%(len(loss_log), np.log10(loss)), end='')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch (before/after):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filename must end in `.weights.h5`. Received: filepath=train_log/0000",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-22-819888735.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mvisualize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mexport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_log/%04d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r step: %d, log10(loss): %.3f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-19-2539483379.py\u001b[0m in \u001b[0;36mexport_model\u001b[0;34m(ca, base_fn)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   cf = ca.call.get_concrete_function(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;34m\"The filename must end in `.weights.h5`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;34mf\"Received: filepath={filepath}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=train_log/0000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAscSKkRaFwp"
      },
      "source": [
        "# Figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqvkfl9W4ODI"
      },
      "source": [
        "#@title Training Progress (Checkpoints)\n",
        "\n",
        "models = []\n",
        "for i in [100, 500, 1000, 4000]:\n",
        "  ca = CAModel()\n",
        "  ca.load_weights('train_log/%04d'%i)\n",
        "  models.append(ca)\n",
        "\n",
        "out_fn = 'train_steps_damage_%d.mp4'%DAMAGE_N\n",
        "x = np.zeros([len(models), 72, 72, CHANNEL_N], np.float32)\n",
        "x[..., 36, 36, 3:] = 1.0\n",
        "with VideoWriter(out_fn) as vid:\n",
        "  for i in tqdm.trange(500):\n",
        "    vis = np.hstack(to_rgb(x))\n",
        "    vid.add(zoom(vis, 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "mvp.ipython_display(out_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeXZKb5v2gxj"
      },
      "source": [
        "#@title Training Progress (Batches)\n",
        "frames = sorted(glob.glob('train_log/batches_*.jpg'))\n",
        "mvp.ImageSequenceClip(frames, fps=10.0).write_videofile('batches.mp4')\n",
        "mvp.ipython_display('batches.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4JAbAJf6Alw"
      },
      "source": [
        "#@title Pool Contents\n",
        "frames = sorted(glob.glob('train_log/*_pool.jpg'))[:80]\n",
        "mvp.ImageSequenceClip(frames, fps=20.0).write_videofile('pool.mp4')\n",
        "mvp.ipython_display('pool.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyxeGm6dJX8D"
      },
      "source": [
        "## Pretrained Models and Figures\n",
        "\n",
        "Please run the cell below to download pretrained models that are used to generate the subsequent figures. The figures generated after this are generated using the pretrained CAs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiGl7S0E6-OA"
      },
      "source": [
        "!wget -O models.zip 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/models.zip?raw=true'\n",
        "!unzip -oq models.zip\n",
        "\n",
        "EMOJI = 'ü¶éüòÄüí•üëÅüê†ü¶ãüêûüï∏ü•®üéÑ'\n",
        "\n",
        "def get_model(emoji='ü¶ã', fire_rate=0.5, use_pool=1, damage_n=3, run=0,\n",
        "              prefix='models/', output='model'):\n",
        "  path = prefix\n",
        "  assert fire_rate in [0.5, 1.0]\n",
        "  if fire_rate==0.5:\n",
        "    path += 'use_sample_pool_%d damage_n_%d '%(use_pool, damage_n)\n",
        "  elif fire_rate==1.0:\n",
        "    path += 'fire_rate_1.0 '\n",
        "  code = hex(ord(emoji))[2:].upper()\n",
        "  path += 'target_emoji_%s run_index_%d/08000'%(code, run)\n",
        "  assert output in ['model', 'json']\n",
        "  if output == 'model':\n",
        "    ca = CAModel(channel_n=16, fire_rate=fire_rate)\n",
        "    ca.load_weights(path)\n",
        "    return ca\n",
        "  elif output == 'json':\n",
        "    return open(path+'.json', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyMms2wKwX9x"
      },
      "source": [
        "atlas = np.hstack([load_emoji(e) for e in EMOJI])\n",
        "imshow(atlas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqgtL5VpLEeL"
      },
      "source": [
        "#@title Teaser\n",
        "models = [get_model(emoji, run=1) for emoji in EMOJI]\n",
        "\n",
        "with VideoWriter('teaser.mp4') as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  # grow\n",
        "  for i in tqdm.trange(200):\n",
        "    k = i//20\n",
        "    if i%20==0 and k<len(EMOJI):\n",
        "      x[k, 32, 32, 3:] = 1.0\n",
        "    vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # damage\n",
        "  mask = PIL.Image.new('L', (64*5, 64*2))\n",
        "  draw = PIL.ImageDraw.Draw(mask)\n",
        "  for i in tqdm.trange(400):\n",
        "    cx, r = i*3-20, 6\n",
        "    y1, y2 = 32+np.sin(i/5+np.pi)*8, 32+64+np.sin(i/5)*8\n",
        "    draw.rectangle((0, 0, 64*5, 64*2), fill=0)\n",
        "    draw.ellipse((cx-r, y1-r, cx+r, y1+r), fill=255)\n",
        "    draw.ellipse((cx-r, y2-r, cx+r, y2+r), fill=255)\n",
        "    x *= 1.0-(np.float32(mask).reshape(2, 64, 5, 64)\n",
        "        .transpose([0, 2, 1, 3]).reshape(10, 64, 64, 1))/255.0\n",
        "    if i<200 or i%2 == 0:\n",
        "      vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  last = zoom(tile2d(to_rgb(x), 5), 2)\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(last*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display('teaser.mp4', loop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O4tzfe-GRJ7"
      },
      "source": [
        "#@title Unstable Patterns\n",
        "!wget -O slider.png 'https://github.com/google-research/self-organising-systems/raw/master/assets/growing_ca/slider.png?raw=true'\n",
        "\n",
        "import PIL.ImageFont\n",
        "from matplotlib import font_manager as fm\n",
        "font_fn = fm.findfont(fm.FontProperties())\n",
        "font = PIL.ImageFont.truetype(font_fn, 20)\n",
        "\n",
        "models = [get_model(ch, use_pool=0, damage_n=0) for ch in EMOJI]\n",
        "fn = 'unstable.mp4'\n",
        "with VideoWriter(fn) as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  x[:, 32, 32, 3:] = 1.0\n",
        "  # grow\n",
        "  slider = PIL.Image.open(\"slider.png\")\n",
        "  for i in tqdm.trange(1000):\n",
        "    if i<200 or i%5 == 0:\n",
        "      vis = zoom(tile2d(to_rgb(x), 5), 4).clip(0, 1)\n",
        "      vis_extended = np.concatenate((vis, np.ones((164, vis.shape[1], 3))), axis=0)\n",
        "      im = np.uint8(vis_extended*255)\n",
        "      im = PIL.Image.fromarray(im)\n",
        "      im.paste(slider, box=(20, vis.shape[0]+20))\n",
        "      draw = PIL.ImageDraw.Draw(im)\n",
        "      p_x = (14 + (610/1000)*i)*2.0\n",
        "      draw.rectangle([p_x, vis.shape[0]+20+55, p_x+10, vis.shape[0]+20+82], fill=\"#434343bd\")\n",
        "      vid.add(np.uint8(im))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(vis_extended*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display(fn, loop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CVR9MeYnjuY"
      },
      "source": [
        "#@title Rotation\n",
        "row_size = 4\n",
        "models_of_interest = [\"ü¶ã\",\"ü¶é\",\"üê†\",\"üòÄ\"]\n",
        "num_images = 16\n",
        "imgs = []\n",
        "start_angle = np.random.randint(13, 76)\n",
        "\n",
        "for i in np.arange(num_images):\n",
        "  ang = start_angle + i * np.random.randint(36, 111)\n",
        "  ang = ang/360.0 * 2 * np.pi\n",
        "  if i % row_size == 0:\n",
        "    ca = get_model(models_of_interest[i // row_size])\n",
        "  x = np.zeros([1, 56, 56, CHANNEL_N], np.float32)\n",
        "  x[:, 28, 28, 3:] = 1.0\n",
        "  for i in range(500):\n",
        "    ang = tf.constant(ang, tf.float32)\n",
        "    x = ca(x, angle=ang)\n",
        "  imgs.append(to_rgb(x)[0])\n",
        "# Assumes the result is a multiple of row_size\n",
        "assert len(imgs) % row_size == 0\n",
        "imgs = zip(*(iter(imgs),) * row_size)\n",
        "\n",
        "imgs_arr = np.concatenate([np.hstack(im_row) for im_row in imgs])\n",
        "vis = zoom(imgs_arr, 4)\n",
        "\n",
        "imshow(vis, fmt='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5JRLGxX1dnX"
      },
      "source": [
        "#@title Regeneration (trained without damage)\n",
        "models = [get_model(ch, damage_n=0) for ch in 'üòÄü¶ãü¶é']\n",
        "with VideoWriter('regen1.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i < 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen1.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDzJM69u4_8p"
      },
      "source": [
        "#@title Regeneration (trained with damage)\n",
        "models = [get_model(ch, damage_n=3) for ch in 'üòÄü¶ãü¶é']\n",
        "with VideoWriter('regen2.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i < 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen2.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ1u2MqFy7Ni"
      },
      "source": [
        "#@title Planarian\n",
        "!wget -O planarian.zip 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/planarian.zip?raw=true'\n",
        "!unzip -oq planarian.zip -d planarian\n",
        "\n",
        "ca = CAModel()\n",
        "ca.load_weights('planarian/train_log/8000')\n",
        "\n",
        "x = np.zeros([1, 64, 96, CHANNEL_N], np.float32)\n",
        "x[:, 32, 48, 3:] = 1.0\n",
        "with VideoWriter('planarian.mp4', 30.0) as vid:\n",
        "  for i in range(400):\n",
        "    vid.add(zoom(to_rgb(x[0])))\n",
        "    x = ca(x, angle=np.pi/2.0)\n",
        "    if i==150:\n",
        "      x = x.numpy()\n",
        "      for k in range(24):\n",
        "        x[:,:24] = np.roll(x[:,:24], 1, 2)\n",
        "        x[:,-24:] = np.roll(x[:,-24:], -1, 2)\n",
        "        vid.add(zoom(to_rgb(x[0])))\n",
        "      for k in range(20):\n",
        "        vid.add(zoom(to_rgb(x[0])))\n",
        "\n",
        "mvp.ipython_display('planarian.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M-oDuhea7bR"
      },
      "source": [
        "# Interactive Demos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7ypa-b7_fTn"
      },
      "source": [
        "#@title TensorFlow.js Demo {run:\"auto\", vertical-output: true}\n",
        "#@markdown Select \"CHECKPOINT\" model to load the checkpoint created by running cells from the \"Training\" section of this notebook\n",
        "import IPython.display\n",
        "\n",
        "model = \"CHECKPOINT\"  #@param ['CHECKPOINT', 'üòÄ 1F600', 'üí• 1F4A5', 'üëÅ 1F441', 'ü¶é 1F98E', 'üê† 1F420', 'ü¶ã 1F98B', 'üêû 1F41E', 'üï∏ 1F578', 'ü•® 1F968', 'üéÑ 1F384']\n",
        "model_type = '3 regenerating'  #@param ['1 naive', '2 persistent', '3 regenerating']\n",
        "\n",
        "#@markdown Shift-click to seed the pattern\n",
        "\n",
        "if model != 'CHECKPOINT':\n",
        "  code = model.split(' ')[1]\n",
        "  emoji = chr(int(code, 16))\n",
        "  experiment_i = int(model_type.split()[0])-1\n",
        "  use_pool = (0, 1, 1)[experiment_i]\n",
        "  damage_n = (0, 0, 3)[experiment_i]\n",
        "  model_str = get_model(emoji, use_pool=use_pool, damage_n=damage_n, output='json')\n",
        "else:\n",
        "  last_checkpoint_fn = sorted(glob.glob('train_log/*.json'))[-1]\n",
        "  model_str = open(last_checkpoint_fn).read()\n",
        "\n",
        "data_js = '''\n",
        "  window.GRAPH_URL = URL.createObjectURL(new Blob([`%s`], {type: 'application/json'}));\n",
        "'''%(model_str)\n",
        "\n",
        "display(IPython.display.Javascript(data_js))\n",
        "\n",
        "\n",
        "IPython.display.HTML('''\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.3.0/dist/tf.min.js\"></script>\n",
        "\n",
        "<canvas id='canvas' style=\"border: 1px solid black; image-rendering: pixelated;\"></canvas>\n",
        "\n",
        "<script>\n",
        "  \"use strict\";\n",
        "\n",
        "  const sleep = (ms)=>new Promise(resolve => setTimeout(resolve, ms));\n",
        "\n",
        "  const parseConsts = model_graph=>{\n",
        "    const dtypes = {'DT_INT32':['int32', 'intVal', Int32Array],\n",
        "                    'DT_FLOAT':['float32', 'floatVal', Float32Array]};\n",
        "\n",
        "    const consts = {};\n",
        "    model_graph.modelTopology.node.filter(n=>n.op=='Const').forEach((node=>{\n",
        "      const v = node.attr.value.tensor;\n",
        "      const [dtype, field, arrayType] = dtypes[v.dtype];\n",
        "      if (!v.tensorShape.dim) {\n",
        "        consts[node.name] = [tf.scalar(v[field][0], dtype)];\n",
        "      } else {\n",
        "        // if there is a 0-length dimension, the exported graph json lacks \"size\"\n",
        "        const shape = v.tensorShape.dim.map(d=>(!d.size) ? 0 : parseInt(d.size));\n",
        "        let arr;\n",
        "        if (v.tensorContent) {\n",
        "          const data = atob(v.tensorContent);\n",
        "          const buf = new Uint8Array(data.length);\n",
        "          for (var i=0; i<data.length; ++i) {\n",
        "            buf[i] = data.charCodeAt(i);\n",
        "          }\n",
        "          arr = new arrayType(buf.buffer);\n",
        "        } else {\n",
        "          const size = shape.reduce((a, b)=>a*b);\n",
        "          arr = new arrayType(size);\n",
        "          if (size) {\n",
        "            arr.fill(v[field][0]);\n",
        "          }\n",
        "        }\n",
        "        consts[node.name] = [tf.tensor(arr, shape, dtype)];\n",
        "      }\n",
        "    }));\n",
        "    return consts;\n",
        "  }\n",
        "\n",
        "  const run = async ()=>{\n",
        "    const r = await fetch(GRAPH_URL);\n",
        "    const consts = parseConsts(await r.json());\n",
        "\n",
        "    const model = await tf.loadGraphModel(GRAPH_URL);\n",
        "    Object.assign(model.weights, consts);\n",
        "\n",
        "    let seed = new Array(16).fill(0).map((x, i)=>i<3?0:1);\n",
        "    seed = tf.tensor(seed, [1, 1, 1, 16]);\n",
        "\n",
        "    const D = 96;\n",
        "    const initState = tf.tidy(()=>{\n",
        "      const D2 = D/2;\n",
        "      const a = seed.pad([[0, 0], [D2-1, D2], [D2-1, D2], [0,0]]);\n",
        "      return a;\n",
        "    });\n",
        "\n",
        "    const state = tf.variable(initState);\n",
        "    const [_, h, w, ch] = state.shape;\n",
        "\n",
        "    const damage = (x, y, r)=>{\n",
        "      tf.tidy(()=>{\n",
        "        const rx = tf.range(0, w).sub(x).div(r).square().expandDims(0);\n",
        "        const ry = tf.range(0, h).sub(y).div(r).square().expandDims(1);\n",
        "        const mask = rx.add(ry).greater(1.0).expandDims(2);\n",
        "        state.assign(state.mul(mask));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    const plantSeed = (x, y)=>{\n",
        "      const x2 = w-x-seed.shape[2];\n",
        "      const y2 = h-y-seed.shape[1];\n",
        "      if (x<0 || x2<0 || y2<0 || y2<0)\n",
        "        return;\n",
        "      tf.tidy(()=>{\n",
        "        const a = seed.pad([[0, 0], [y, y2], [x, x2], [0,0]]);\n",
        "        state.assign(state.add(a));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    const scale = 4;\n",
        "\n",
        "    const canvas = document.getElementById('canvas');\n",
        "    const ctx = canvas.getContext('2d');\n",
        "    canvas.width = w;\n",
        "    canvas.height = h;\n",
        "    canvas.style.width = `${w*scale}px`;\n",
        "    canvas.style.height = `${h*scale}px`;\n",
        "\n",
        "    canvas.onmousedown = e=>{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "        const y = Math.floor(e.clientY/scale);\n",
        "        if (e.buttons == 1) {\n",
        "          if (e.shiftKey) {\n",
        "            plantSeed(x, y);\n",
        "          } else {\n",
        "            damage(x, y, 8);\n",
        "          }\n",
        "        }\n",
        "    }\n",
        "    canvas.onmousemove = e=>{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "      const y = Math.floor(e.clientY/scale);\n",
        "      if (e.buttons == 1 && !e.shiftKey) {\n",
        "        damage(x, y, 8);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    function step() {\n",
        "      tf.tidy(()=>{\n",
        "        state.assign(model.execute(\n",
        "            {x:state, fire_rate:tf.tensor(0.5),\n",
        "            angle:tf.tensor(0.0), step_size:tf.tensor(1.0)}, ['Identity']));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    function render() {\n",
        "      step();\n",
        "\n",
        "      const imageData = tf.tidy(()=>{\n",
        "        const rgba = state.slice([0, 0, 0, 0], [-1, -1, -1, 4]);\n",
        "        const a = state.slice([0, 0, 0, 3], [-1, -1, -1, 1]);\n",
        "        const img = tf.tensor(1.0).sub(a).add(rgba).mul(255);\n",
        "        const rgbaBytes = new Uint8ClampedArray(img.dataSync());\n",
        "        return new ImageData(rgbaBytes, w, h);\n",
        "      });\n",
        "      ctx.putImageData(imageData, 0, 0);\n",
        "\n",
        "      requestAnimationFrame(render);\n",
        "    }\n",
        "    render();\n",
        "  }\n",
        "  run();\n",
        "\n",
        "</script>\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POma99rMIfV4"
      },
      "source": [
        "#@title WebGL Demo\n",
        "\n",
        "#@markdown This code exports quantized models for the WebGL demo that is used in the article.\n",
        "#@markdown The demo code can be found at https://github.com/distillpub/post--growing-ca/blob/master/public/ca.js\n",
        "\n",
        "def pack_layer(weight, bias, outputType=np.uint8):\n",
        "  in_ch, out_ch = weight.shape\n",
        "  assert (in_ch%4==0) and (out_ch%4==0) and (bias.shape==(out_ch,))\n",
        "  weight_scale, bias_scale = 1.0, 1.0\n",
        "  if outputType == np.uint8:\n",
        "    weight_scale = 2.0*np.abs(weight).max()\n",
        "    bias_scale = 2.0*np.abs(bias).max()\n",
        "    weight = np.round((weight/weight_scale+0.5)*255)\n",
        "    bias = np.round((bias/bias_scale+0.5)*255)\n",
        "  packed = np.vstack([weight, bias[None,...]])\n",
        "  packed = packed.reshape(in_ch+1, out_ch//4, 4)\n",
        "  packed = outputType(packed)\n",
        "  packed_b64 = base64.b64encode(packed.tobytes()).decode('ascii')\n",
        "  return {'data_b64': packed_b64, 'in_ch': in_ch, 'out_ch': out_ch,\n",
        "          'weight_scale': weight_scale, 'bias_scale': bias_scale,\n",
        "          'type': outputType.__name__}\n",
        "\n",
        "def export_ca_to_webgl_demo(ca, outputType=np.uint8):\n",
        "  # reorder the first layer inputs to meet webgl demo perception layout\n",
        "  chn = ca.channel_n\n",
        "  w1 = ca.weights[0][0, 0].numpy()\n",
        "  w1 = w1.reshape(chn, 3, -1).transpose(1, 0, 2).reshape(3*chn, -1)\n",
        "  layers = [\n",
        "      pack_layer(w1, ca.weights[1].numpy(), outputType),\n",
        "      pack_layer(ca.weights[2][0, 0].numpy(), ca.weights[3].numpy(), outputType)\n",
        "  ]\n",
        "  return json.dumps(layers)\n",
        "\n",
        "with zipfile.ZipFile('webgl_models8.zip', 'w') as zf:\n",
        "  for e in EMOJI:\n",
        "    zf.writestr('ex1_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=0, damage_n=0)))\n",
        "    run = 1 if e in 'üòÄüï∏' else 0  # select runs that happen to quantize better\n",
        "    zf.writestr('ex2_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=0, run=run)))\n",
        "    run = 1 if e in 'ü¶é' else 0    # select runs that happen to quantize better\n",
        "    zf.writestr('ex3_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=3, run=run)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}