{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Growing Neural Cellular Automata",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28S76DVlfCMZ"
      },
      "source": [
        "# Growing Neural Cellular Automata\n",
        "\n",
        "This notebook contains code to reproduce experiments and figures for the [\"Growing Neural Cellular Automata\"](http://distill.pub/2020/growing-ca) article.\n",
        "\n",
        "Copyright 2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5wi_r4gyzFr"
      },
      "source": [
        "#@title Imports and Notebook Utilities\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "clear_output()\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def imshow(a, fmt='jpeg'):\n",
        "  display(Image(data=imencode(a, fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(len(a))))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w-len(a))%w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = len(a)//w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename, fps=30.0, **kw):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kw)\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in [np.float32, np.float64]:\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if len(img.shape) == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer:\n",
        "      self.writer.close()\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *kw):\n",
        "    self.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR6I1JONmWBb"
      },
      "source": [
        "#@title Cellular Automata Parameters\n",
        "CHANNEL_N = 16        # Number of CA state channels\n",
        "TARGET_PADDING = 16   # Number of pixels used to pad the target image border\n",
        "TARGET_SIZE = 40\n",
        "BATCH_SIZE = 8\n",
        "POOL_SIZE = 1024\n",
        "CELL_FIRE_RATE = 0.5\n",
        "\n",
        "TARGET_EMOJI = \"🦎\" #@param {type:\"string\"}\n",
        "\n",
        "EXPERIMENT_TYPE = \"Regenerating\" #@param [\"Growing\", \"Persistent\", \"Regenerating\"]\n",
        "EXPERIMENT_MAP = {\"Growing\":0, \"Persistent\":1, \"Regenerating\":2}\n",
        "EXPERIMENT_N = EXPERIMENT_MAP[EXPERIMENT_TYPE]\n",
        "\n",
        "USE_PATTERN_POOL = [0, 1, 1][EXPERIMENT_N]\n",
        "DAMAGE_N = [0, 0, 3][EXPERIMENT_N]  # Number of patterns to damage in a batch"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCbPFbI_zosW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "840548b8-dd97-4939-a8c0-cc906aa6a5d1"
      },
      "source": [
        "#@title CA Model and Utilities\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "def load_image(url, max_size=TARGET_SIZE):\n",
        "  r = requests.get(url)\n",
        "  img = PIL.Image.open(io.BytesIO(r.content))\n",
        "  img.thumbnail((max_size, max_size), PIL.Image.LANCZOS)\n",
        "  img = np.float32(img)/255.0\n",
        "  # premultiply RGB by Alpha\n",
        "  img[..., :3] *= img[..., 3:]\n",
        "  return img\n",
        "\n",
        "def load_emoji(emoji):\n",
        "  code = hex(ord(emoji))[2:].lower()\n",
        "  url = 'https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
        "  return load_image(url)\n",
        "\n",
        "\n",
        "def to_rgba(x):\n",
        "  return x[..., :4]\n",
        "\n",
        "def to_alpha(x):\n",
        "  return tf.clip_by_value(x[..., 3:4], 0.0, 1.0)\n",
        "\n",
        "def to_rgb(x):\n",
        "  # assume rgb premultiplied by alpha\n",
        "  rgb, a = x[..., :3], to_alpha(x)\n",
        "  return 1.0-a+rgb\n",
        "\n",
        "def get_living_mask(x):\n",
        "  alpha = x[:, :, :, 3:4]\n",
        "  return tf.nn.max_pool2d(alpha, 3, [1, 1, 1, 1], 'SAME') > 0.1\n",
        "\n",
        "def make_seed(size, n=1):\n",
        "  x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
        "  x[:, size//2, size//2, 3:] = 1.0\n",
        "  return x\n",
        "\n",
        "\n",
        "class CAModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
        "    super().__init__()\n",
        "    self.channel_n = channel_n\n",
        "    self.fire_rate = fire_rate\n",
        "\n",
        "    self.dmodel = tf.keras.Sequential([\n",
        "          Conv2D(128, 1, activation=tf.nn.relu),\n",
        "          Conv2D(self.channel_n, 1, activation=None,\n",
        "              kernel_initializer=tf.zeros_initializer),\n",
        "    ])\n",
        "\n",
        "    self(tf.zeros([1, 3, 3, channel_n]))  # dummy call to build the model\n",
        "\n",
        "  @tf.function\n",
        "  def perceive(self, x, angle=0.0):\n",
        "    identify = np.float32([0, 1, 0])\n",
        "    identify = np.outer(identify, identify)\n",
        "    dx = np.outer([1, 2, 1], [-1, 0, 1]) / 8.0  # Sobel filter\n",
        "    dy = dx.T\n",
        "    c, s = tf.cos(angle), tf.sin(angle)\n",
        "    kernel = tf.stack([identify, c*dx-s*dy, s*dx+c*dy], -1)[:, :, None, :]\n",
        "    kernel = tf.repeat(kernel, self.channel_n, 2)\n",
        "    y = tf.nn.depthwise_conv2d(x, kernel, [1, 1, 1, 1], 'SAME')\n",
        "    return y\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
        "    pre_life_mask = get_living_mask(x)\n",
        "\n",
        "    y = self.perceive(x, angle)\n",
        "    dx = self.dmodel(y)*step_size\n",
        "    if fire_rate is None:\n",
        "      fire_rate = self.fire_rate\n",
        "    update_mask = tf.random.uniform(tf.shape(x[:, :, :, :1])) <= fire_rate\n",
        "    x += dx * tf.cast(update_mask, tf.float32)\n",
        "\n",
        "    post_life_mask = get_living_mask(x)\n",
        "    life_mask = pre_life_mask & post_life_mask\n",
        "    return x * tf.cast(life_mask, tf.float32)\n",
        "\n",
        "\n",
        "CAModel().dmodel.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m6,272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │         \u001b[38;5;34m2,064\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,336\u001b[0m (32.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,336</span> (32.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,336\u001b[0m (32.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,336</span> (32.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDX5HL7VLd0z"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeWf6HeTe8kM"
      },
      "source": [
        "#@title Train Utilities (SamplePool, Model Export, Damage)\n",
        "from google.protobuf.json_format import MessageToDict\n",
        "from tensorflow.python.framework import convert_to_constants\n",
        "\n",
        "class SamplePool:\n",
        "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
        "    self._parent = _parent\n",
        "    self._parent_idx = _parent_idx\n",
        "    self._slot_names = slots.keys()\n",
        "    self._size = None\n",
        "    for k, v in slots.items():\n",
        "      if self._size is None:\n",
        "        self._size = len(v)\n",
        "      assert self._size == len(v)\n",
        "      setattr(self, k, np.asarray(v))\n",
        "\n",
        "  def sample(self, n):\n",
        "    idx = np.random.choice(self._size, n, False)\n",
        "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
        "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
        "    return batch\n",
        "\n",
        "  def commit(self):\n",
        "    for k in self._slot_names:\n",
        "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
        "\n",
        "@tf.function\n",
        "def make_circle_masks(n, h, w):\n",
        "  x = tf.linspace(-1.0, 1.0, w)[None, None, :]\n",
        "  y = tf.linspace(-1.0, 1.0, h)[None, :, None]\n",
        "  center = tf.random.uniform([2, n, 1, 1], -0.5, 0.5)\n",
        "  r = tf.random.uniform([n, 1, 1], 0.1, 0.4)\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = tf.cast(x*x+y*y < 1.0, tf.float32)\n",
        "  return mask\n",
        "\n",
        "def export_model(ca, base_fn):\n",
        "  ca.save_weights(base_fn+'.weights.h5')\n",
        "\n",
        "  cf = ca.call.get_concrete_function(\n",
        "      x=tf.TensorSpec([None, None, None, CHANNEL_N]),\n",
        "      fire_rate=tf.constant(0.5),\n",
        "      angle=tf.constant(0.0),\n",
        "      step_size=tf.constant(1.0))\n",
        "  cf = convert_to_constants.convert_variables_to_constants_v2(cf)\n",
        "  graph_def = cf.graph.as_graph_def()\n",
        "  graph_json = MessageToDict(graph_def)\n",
        "  graph_json['versions'] = dict(producer='1.14', minConsumer='1.14')\n",
        "  model_json = {\n",
        "      'format': 'graph-model',\n",
        "      'modelTopology': graph_json,\n",
        "      'weightsManifest': [],\n",
        "  }\n",
        "  with open(base_fn+'.json', 'w') as f:\n",
        "    json.dump(model_json, f)\n",
        "\n",
        "def generate_pool_figures(pool, step_i):\n",
        "  tiled_pool = tile2d(to_rgb(pool.x[:49]))\n",
        "  fade = np.linspace(1.0, 0.0, 72)\n",
        "  ones = np.ones(72)\n",
        "  tiled_pool[:, :72] += (-tiled_pool[:, :72] + ones[None, :, None]) * fade[None, :, None]\n",
        "  tiled_pool[:, -72:] += (-tiled_pool[:, -72:] + ones[None, :, None]) * fade[None, ::-1, None]\n",
        "  tiled_pool[:72, :] += (-tiled_pool[:72, :] + ones[:, None, None]) * fade[:, None, None]\n",
        "  tiled_pool[-72:, :] += (-tiled_pool[-72:, :] + ones[:, None, None]) * fade[::-1, None, None]\n",
        "  imwrite('train_log/%04d_pool.jpg'%step_i, tiled_pool)\n",
        "\n",
        "def visualize_batch(x0, x, step_i):\n",
        "  vis0 = np.hstack(to_rgb(x0).numpy())\n",
        "  vis1 = np.hstack(to_rgb(x).numpy())\n",
        "  vis = np.vstack([vis0, vis1])\n",
        "  imwrite('train_log/batches_%04d.jpg'%step_i, vis)\n",
        "  print('batch (before/after):')\n",
        "  imshow(vis)\n",
        "\n",
        "def plot_loss(loss_log):\n",
        "  pl.figure(figsize=(10, 4))\n",
        "  pl.title('Loss history (log10)')\n",
        "  pl.plot(np.log10(loss_log), '.', alpha=0.1)\n",
        "  pl.show()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKlA50h0jlvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "b616495c-f654-4afe-ae47-b063b847ecc8"
      },
      "source": [
        "#@title Choose Target Image { vertical-output: true}\n",
        "#url = 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/planaria2_48.png?raw=true'\n",
        "#target_img = load_image(url, 48)\n",
        "\n",
        "target_img = load_emoji(TARGET_EMOJI)\n",
        "imshow(zoom(to_rgb(target_img), 2), fmt='png')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak5rBmbxmHV7"
      },
      "source": [
        "#@title Initialize Training { vertical-output: true}\n",
        "\n",
        "p = TARGET_PADDING\n",
        "pad_target = tf.pad(target_img, [(p, p), (p, p), (0, 0)])\n",
        "h, w = pad_target.shape[:2]\n",
        "seed = np.zeros([h, w, CHANNEL_N], np.float32)\n",
        "seed[h//2, w//2, 3:] = 1.0\n",
        "\n",
        "def loss_f(x):\n",
        "  return tf.reduce_mean(tf.square(to_rgba(x)-pad_target), [-2, -3, -1])\n",
        "\n",
        "ca = CAModel()\n",
        "\n",
        "loss_log = []\n",
        "\n",
        "lr = 2e-3\n",
        "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    [2000], [lr, lr*0.1])\n",
        "trainer = tf.keras.optimizers.Adam(lr_sched)\n",
        "\n",
        "loss0 = loss_f(seed).numpy()\n",
        "pool = SamplePool(x=np.repeat(seed[None, ...], POOL_SIZE, 0))\n",
        "\n",
        "!mkdir -p train_log && rm -f train_log/*"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzP_vDchq0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "d61d7996-3588-4cb5-82ef-ed4f2d614c6a"
      },
      "source": [
        "#@title Training Loop {vertical-output: true}\n",
        "\n",
        "@tf.function\n",
        "def train_step(x):\n",
        "  iter_n = tf.random.uniform([], 64, 96, tf.int32)\n",
        "  with tf.GradientTape() as g:\n",
        "    for i in tf.range(iter_n):\n",
        "      x = ca(x)\n",
        "    loss = tf.reduce_mean(loss_f(x))\n",
        "  grads = g.gradient(loss, ca.weights)\n",
        "  grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
        "  trainer.apply_gradients(zip(grads, ca.weights))\n",
        "  return x, loss\n",
        "\n",
        "for i in range(8000+1):\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch = pool.sample(BATCH_SIZE)\n",
        "    x0 = batch.x\n",
        "    loss_rank = loss_f(x0).numpy().argsort()[::-1]\n",
        "    x0 = x0[loss_rank]\n",
        "    x0[:1] = seed\n",
        "    if DAMAGE_N:\n",
        "      damage = 1.0-make_circle_masks(DAMAGE_N, h, w).numpy()[..., None]\n",
        "      x0[-DAMAGE_N:] *= damage\n",
        "  else:\n",
        "    x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
        "\n",
        "  x, loss = train_step(x0)\n",
        "\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch.x[:] = x\n",
        "    batch.commit()\n",
        "\n",
        "  step_i = len(loss_log)\n",
        "  loss_log.append(loss.numpy())\n",
        "\n",
        "  if step_i%10 == 0:\n",
        "    generate_pool_figures(pool, step_i)\n",
        "  if step_i%100 == 0:\n",
        "    clear_output()\n",
        "    visualize_batch(x0, x, step_i)\n",
        "    plot_loss(loss_log)\n",
        "    export_model(ca, 'train_log/%04d'%step_i)\n",
        "\n",
        "  print('\\r step: %d, log10(loss): %.3f'%(len(loss_log), np.log10(loss)), end='')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch (before/after):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA08AAAF2CAYAAAC21KNWAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOEdJREFUeJzt3X10VNW9//HP5GkghCSQB5OUBIFYghQxDSUNl2oQSkJRCKV4UZoSFhdLRBGlsVAsiIoRoddYem25V0uCVYvUCy6hIBgCFykIxkZEITxIDE8BDWZCFBKY7N8f/pg65IEzmCGRvF9rnaWzzz77fHc4K/jxnLPHZowxAgAAAAA0y6e1CwAAAACAbwPCEwAAAABYQHgCAAAAAAsITwAAAABgAeEJAAAAACwgPAEAAACABYQnAAAAALCA8AQAAAAAFhCeAAAAAMACwhMAwOuysrIUFBRkqa/NZtOjjz7q3YKusiNHjqhDhw7atm2bqy0rK0vXX3996xV1hdavX6+goCB9+umnrV0KAFx1hCcA+BbLz8+XzWbTu+++29qltKqXX35ZeXl5rV1Gkx577DElJyfr3/7t367qeWtqajRv3jylp6era9eustlsys/Pb7L/3r17lZ6erqCgIHXt2lWZmZkNQlJ6erri4+OVm5vr5eoBoO0hPAEA2pSzZ8/qkUce8eiYthyePv30UxUUFGjq1KlX/dyfffaZHnvsMe3du1f9+/dvtu/Ro0d1yy236ODBg3ryySf1q1/9SmvXrtWPf/xj1dXVufX95S9/qaVLl+rMmTPeLB8A2hzCEwCgTenQoYP8/PxauwxduHChQWi4En/5y1/k5+enO+64owWq8kx0dLROnDihTz75RIsWLWq275NPPqkvvvhCmzZt0vTp0/Wb3/xGr776qt5///0Gd6vGjh2r2tparVy50ovVA0DbQ3gCgHbgn//8p0aMGKHg4GAFBQVp6NCh2rFjh1uf8+fPa/78+brhhhvUoUMHhYWFafDgwdq4caOrT0VFhSZNmqRu3brJbrcrOjpao0ePVllZmaU6jh07poyMDAUFBSkiIkK/+tWv5HQ63fpc+s7TmTNnNGPGDF1//fWy2+2KjIzUj3/8Y7333nuSpNTUVK1du1affPKJbDabbDab27tEp06d0uTJk3XdddepQ4cO6t+/vwoKCtzOWVZWJpvNpsWLFysvL0+9evWS3W7Xzp071alTJz3wwAMN5nL06FH5+vpe9vG11atXKzk52dI7X1988YVmzpyp2NhY2e129e7dW4sXL5Yxxq3f2bNnNX36dIWHh6tz584aNWqUjh071uBnZ7fbFRUVddnzStJrr72m22+/XXFxca62YcOG6bvf/a5effVVt76RkZG66aab9Prrr1saGwCuFa3/v/YAAF714Ycf6kc/+pGCg4P18MMPy9/fX0uXLlVqaqq2bNmi5ORkSdKjjz6q3Nxc/cd//IcGDhyo6upqvfvuu3rvvff04x//WNJXdxw+/PBD3X///br++ut16tQpbdy4UeXl5Zdd/MDpdCotLU3JyclavHix3nrrLf3ud79Tr169lJ2d3eRxU6dO1d/+9jfdd999uvHGG1VZWam3335be/fu1fe//33NmTNHDodDR48e1TPPPCNJrqBy9uxZpaam6uDBg7rvvvvUo0cPrVy5UllZWaqqqmoQipYtW6Zz587pnnvukd1uV1xcnMaMGaMVK1boP//zP+Xr6+vq+8orr8gYowkTJjRZ+/nz57Vr165m53eRMUajRo1SUVGRJk+erJtvvllvvvmmcnJydOzYMdfcpK8Wm3j11VeVmZmpH/7wh9qyZYtGjhx52XM05dixYzp16pQGDBjQYN/AgQP197//vUF7UlKSVq9efcXnBIBvJQMA+NZatmyZkWR27drVZJ+MjAwTEBBgDh065Go7fvy46dy5s7nllltcbf379zcjR45scpzPP//cSDKLFi3yuM6JEycaSeaxxx5za09MTDRJSUlubZLMvHnzXJ9DQkLMtGnTmh1/5MiRpnv37g3a8/LyjCTzl7/8xdVWV1dnUlJSTFBQkKmurjbGGHP48GEjyQQHB5tTp065jfHmm28aSWbdunVu7TfddJO59dZbm63r4MGDRpJZsmRJg30TJ050q3n16tVGknniiSfc+v3sZz8zNpvNHDx40BhjTHFxsZFkZsyY4dYvKyurwc/u63bt2mUkmWXLljW5b/ny5Q325eTkGEnm3Llzbu1PPvmkkWROnjzZ6PkA4FrEY3sAcA1zOp3asGGDMjIy1LNnT1d7dHS07r77br399tuqrq6WJIWGhurDDz/UgQMHGh2rY8eOCggI0ObNm/X5559fUT2XLprwox/9SB9//HGzx4SGhuqdd97R8ePHPT7f3//+d0VFRemuu+5ytfn7+2v69OmqqanRli1b3PqPHTtWERERbm3Dhg1TTEyMXnrpJVfbnj17tHv3bv385z9v9vyVlZWSpC5duliq1dfXV9OnT3drnzlzpowxWrdunaSvlgqXpHvvvdet3/3333/ZczTl7Nmzkr56zO9SHTp0cOtz0cU5ffbZZ1d8XgD4tiE8AcA17NNPP9WXX36p3r17N9jXp08f1dfX68iRI5K+Wk67qqpK3/3ud9WvXz/l5ORo9+7drv52u10LFy7UunXrdN111+mWW27R008/rYqKCku1dOjQoUEw6dKly2WD2NNPP609e/YoNjZWAwcO1KOPPnrZwHXRJ598ohtuuEE+Pu5/3fXp08e1/+t69OjRYAwfHx9NmDBBq1ev1pdffilJeumll9ShQweNGzfOUh3mkneWmqo1JiZGnTt3brbWTz75RD4+Pg1qjY+Pt1RLYzp27ChJqq2tbbDv3Llzbn0uujgnm812xecFgG8bwhMAQJJ0yy236NChQ/rzn/+s733ve3r++ef1/e9/X88//7yrz4wZM7R//37l5uaqQ4cO+u1vf6s+ffron//852XH//r7Qp6488479fHHH2vJkiWKiYnRokWL1LdvX9edmJZ0aUC46Be/+IVqamq0evVqGWP08ssv6/bbb1dISEiz44WFhUnSFd+pu1qio6MlSSdOnGiw78SJE+ratWuDu1IX5xQeHu79AgGgjSA8AcA1LCIiQoGBgSotLW2wb9++ffLx8VFsbKyrrWvXrpo0aZJeeeUVHTlyRDfddJPb6m2S1KtXL82cOVMbNmzQnj17VFdXp9/97ndenUd0dLTuvfderV69WocPH1ZYWJgWLFjg2t/U3Y/u3bvrwIEDqq+vd2vft2+fa78V3/ve95SYmKiXXnpJW7duVXl5uTIzMy97XFxcnDp27KjDhw9ftm/37t11/PjxBt+ddGmt3bt3V319fYMxDx48aGkujfnOd76jiIiIRr9seefOnbr55psbtB8+fFjh4eEN7iYCwLWM8AQA1zBfX18NHz5cr7/+utty4idPntTLL7+swYMHKzg4WNK/3s+5KCgoSPHx8a5Hub788kvXI1wX9erVS507d270ca+W4HQ65XA43NoiIyMVExPjds5OnTo16CdJP/nJT1RRUaEVK1a42i5cuKAlS5YoKChIt956q+VaMjMztWHDBuXl5SksLEwjRoy47DH+/v4aMGBAo6GksVqdTqf+8Ic/uLU/88wzstlsrvOlpaVJkp577jm3fkuWLLE6lUaNHTtWa9ascT3GKUmFhYXav39/o48nFhcXKyUl5RudEwC+bViqHACuAX/+859dCwl83QMPPKAnnnhCGzdu1ODBg3XvvffKz89PS5cuVW1trZ5++mlX3xtvvFGpqalKSkpS165d9e6777qWCJek/fv3a+jQobrzzjt14403ys/PT6tWrdLJkyc1fvx4r8zrzJkz6tatm372s5+pf//+CgoK0ltvvaVdu3a53e1KSkrSihUr9NBDD+kHP/iBgoKCdMcdd+iee+7R0qVLlZWVpeLiYl1//fX629/+pm3btikvL6/B+0XNufvuu/Xwww9r1apVys7Olr+/v6XjRo8erTlz5qi6utoVVBtzxx13aMiQIZozZ47KysrUv39/bdiwQa+//rpmzJihXr16ueY6duxY5eXlqbKy0rVU+f79+yU1vAv3hz/8QVVVVa4FN9544w0dPXpU0leLTFx89PA3v/mNVq5cqSFDhuiBBx5QTU2NFi1apH79+mnSpEluY546dUq7d+/WtGnTLP0MAOCa0bqL/QEAvomLS5U3tR05csQYY8x7771n0tLSTFBQkAkMDDRDhgwx//jHP9zGeuKJJ8zAgQNNaGio6dixo0lISDALFiwwdXV1xhhjPvvsMzNt2jSTkJBgOnXqZEJCQkxycrJ59dVXL1vnxIkTTadOnRq0z5s3z1z6V5G+ttx2bW2tycnJMf379zedO3c2nTp1Mv379zfPPfec2zE1NTXm7rvvNqGhoUaS2xLgJ0+eNJMmTTLh4eEmICDA9OvXr8Fy3ReXKr/cMuw/+clPjKQGP7vmnDx50vj5+ZkXX3zRrf3SpcqNMebMmTPmwQcfNDExMcbf39/ccMMNZtGiRaa+vt6t3xdffGGmTZtmunbtaoKCgkxGRoYpLS01ksxTTz3l1rd79+5NXh+HDx9267tnzx4zfPhwExgYaEJDQ82ECRNMRUVFgzn98Y9/NIGBga6l3gGgvbAZY2EJIAAAoDFjxuiDDz7w+P2iyZMna//+/dq6dauXKpNKSkqUmJiov/zlL81+cW9LSExMVGpqqtsX9wJAe8A7TwAAWHDixAmtXbvW0kIRl5o3b5527dqlbdu2tUgtl37nkiTl5eXJx8dHt9xyS4ucoynr16/XgQMHNHv2bK+eBwDaIu48AQDQjMOHD2vbtm16/vnntWvXLh06dEhRUVGtWtP8+fNVXFysIUOGyM/PT+vWrdO6detc73gBALyDBSMAAGjGli1bNGnSJMXFxamgoKDVg5MkDRo0SBs3btTjjz+umpoaxcXF6dFHH9WcOXNauzQAuKZx5wkAAAAALOCdJwAAAACwgPAEAAAAABa0y3ee6uvrdfz4cXXu3LnBlwkCAAAAaD+MMTpz5oxiYmLk49P8vaV2GZ6OHz+u2NjY1i4DAAAAQBtx5MgRdevWrdk+7TI8de7cWdJXP6Dg4OBWrgYAAABAa6murlZsbKwrIzSnXYani4/qBQcHE54AAAAAWHqdhwUjAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAs8Gp4WrBggQYNGqTAwECFhoZ6fPzUqVNls9mUl5fX6P7a2lrdfPPNstlsKikp+Ua1AgAAAEBzvBqe6urqNG7cOGVnZ3t87KpVq7Rjxw7FxMQ02efhhx9udj8AAAAAtBSvhqf58+frwQcfVL9+/Tw67tixY7r//vv10ksvyd/fv9E+69at04YNG7R48eKWKBUAAAAAmtXmviS3vr5emZmZysnJUd++fRvtc/LkSU2ZMkWrV69WYGDgVa4QAAAAQHvU5sLTwoUL5efnp+nTpze63xijrKwsTZ06VQMGDFBZWdllx6ytrVVtba3rc3V1dUuVCwAAAKCd8PixvVmzZslmszW77du374qKKS4u1rPPPqv8/HzZbLZG+yxZskRnzpzR7NmzLY+bm5urkJAQ1xYbG3tF9QEAAABov2zGGOPJAZ9++qkqKyub7dOzZ08FBAS4Pufn52vGjBmqqqpq9ri8vDw99NBD8vH5V6ZzOp3y8fFRbGysysrKlJGRoTfeeMMtXDmdTvn6+mrChAkqKChoMG5jd55iY2PlcDgUHBx8uSkDAAAAuEZVV1crJCTEUjbw+LG9iIgIRUREXHFxzcnMzNSwYcPc2tLS0pSZmalJkyZJkn7/+9/riSeecO0/fvy40tLStGLFCiUnJzc6rt1ul91u90rNAAAAANoHr77zVF5ertOnT6u8vFxOp9P1XUzx8fEKCgqSJCUkJCg3N1djxoxRWFiYwsLC3Mbw9/dXVFSUevfuLUmKi4tz239xnF69eqlbt27enA4AAACAdsyr4Wnu3Lluj9ElJiZKkoqKipSamipJKi0tlcPh8GYZAAAAAPCNefzO07XAk+caAQAAAFy7PMkGXv2SXAAAAAC4VhCeAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAsIDwBAAAAgAWEJwAAAACwgPAEAAAAABYQngAAAADAAsITAAAAAFhAeAIAAAAACwhPAAAAAGAB4QkAAAAALCA8AQAAAIAFhCcAAAAAsIDwBAAAAAAWEJ4AAAAAwALCEwAAAABYQHgCAAAAAAsITwAAAABgAeEJAAAAACwgPAEAAACABYQnAAAAALCA8AQAAAAAFhCeAAAAAMACr4WnBQsWaNCgQQoMDFRoaKjHx0+dOlU2m015eXkN9q1du1bJycnq2LGjunTpooyMjG9cLwAAAAA0x2vhqa6uTuPGjVN2drbHx65atUo7duxQTExMg32vvfaaMjMzNWnSJL3//vvatm2b7r777pYoGQAAAACa5OetgefPny9Jys/P9+i4Y8eO6f7779ebb76pkSNHuu27cOGCHnjgAS1atEiTJ092td94443fuF4AAAAAaE6beuepvr5emZmZysnJUd++fRvsf++993Ts2DH5+PgoMTFR0dHRGjFihPbs2dMK1QIAAABoT9pUeFq4cKH8/Pw0ffr0Rvd//PHHkqRHH31UjzzyiNasWaMuXbooNTVVp0+fbnLc2tpaVVdXu20AAAAA4AmPwtOsWbNks9ma3fbt23dFhRQXF+vZZ59Vfn6+bDZbo33q6+slSXPmzNHYsWOVlJSkZcuWyWazaeXKlU2OnZubq5CQENcWGxt7RTUCAAAAaL88eudp5syZysrKarZPz549r6iQrVu36tSpU4qLi3O1OZ1OzZw5U3l5eSorK1N0dLQk93ec7Ha7evbsqfLy8ibHnj17th566CHX5+rqagIUAAAAAI94FJ4iIiIUERHhlUIyMzM1bNgwt7a0tDTXynqSlJSUJLvdrtLSUg0ePFiSdP78eZWVlal79+5Njm2322W3271SNwAAAID2wWur7ZWXl+v06dMqLy+X0+lUSUmJJCk+Pl5BQUGSpISEBOXm5mrMmDEKCwtTWFiY2xj+/v6KiopS7969JUnBwcGaOnWq5s2bp9jYWHXv3l2LFi2SJI0bN85bUwEAAAAA74WnuXPnqqCgwPU5MTFRklRUVKTU1FRJUmlpqRwOh0fjLlq0SH5+fsrMzNTZs2eVnJysTZs2qUuXLi1WOwAAAABcymaMMa1dxNVWXV2tkJAQORwOBQcHt3Y5AAAAAFqJJ9mgTS1VDgAAAABtFeEJAAAAACwgPAEAAACABYQnAAAAALCA8AQAAAAAFhCeAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAsIDwBAAAAgAWEJwAAAACwgPAEAAAAABYQngAAAADAAsITAAAAAFhAeAIAAAAACwhPAAAAAGAB4QkAAAAALCA8AQAAAIAFhCcAAAAAsIDwBAAAAAAWEJ4AAAAAwALCEwAAAABYQHgCAAAAAAsITwAAAABgAeEJAAAAACzwWnhasGCBBg0apMDAQIWGhnp8/NSpU2Wz2ZSXl+fWvn//fo0ePVrh4eEKDg7W4MGDVVRU1DJFAwAAAEATvBae6urqNG7cOGVnZ3t87KpVq7Rjxw7FxMQ02Hf77bfrwoUL2rRpk4qLi9W/f3/dfvvtqqioaImyAQAAAKBRXgtP8+fP14MPPqh+/fp5dNyxY8d0//3366WXXpK/v7/bvs8++0wHDhzQrFmzdNNNN+mGG27QU089pS+//FJ79uxpyfIBAAAAwE2beuepvr5emZmZysnJUd++fRvsDwsLU+/evbV8+XJ98cUXunDhgpYuXarIyEglJSW1QsUAAAAA2gu/1i7g6xYuXCg/Pz9Nnz690f02m01vvfWWMjIy1LlzZ/n4+CgyMlLr169Xly5dmhy3trZWtbW1rs/V1dUtXjsAAACAa5tHd55mzZolm83W7LZv374rKqS4uFjPPvus8vPzZbPZGu1jjNG0adMUGRmprVu3aufOncrIyNAdd9yhEydONDl2bm6uQkJCXFtsbOwV1QgAAACg/bIZY4zVzp9++qkqKyub7dOzZ08FBAS4Pufn52vGjBmqqqpq9ri8vDw99NBD8vH5V55zOp3y8fFRbGysysrKVFhYqOHDh+vzzz9XcHCwq98NN9ygyZMna9asWY2O3didp9jYWDkcDrdxAAAAALQv1dXVCgkJsZQNPHpsLyIiQhEREd+ouKZkZmZq2LBhbm1paWnKzMzUpEmTJElffvmlJLkFrIuf6+vrmxzbbrfLbre3cMUAAAAA2hOvvfNUXl6u06dPq7y8XE6nUyUlJZKk+Ph4BQUFSZISEhKUm5urMWPGKCwsTGFhYW5j+Pv7KyoqSr1795YkpaSkqEuXLpo4caLmzp2rjh076n/+5390+PBhjRw50ltTAQAAAADvhae5c+eqoKDA9TkxMVGSVFRUpNTUVElSaWmpHA6H5THDw8O1fv16zZkzR7fddpvOnz+vvn376vXXX1f//v1btH4AAAAA+DqP3nm6VnjyXCMAAACAa5cn2aBNfc8TAAAAALRVhCcAAAAAsIDwBAAAAAAWEJ4AAAAAwALCEwAAAABYQHgCAAAAAAsITwAAAABgAeEJAAAAACwgPAEAAACABYQnAAAAALCA8AQAAAAAFhCeAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAsIDwBAAAAgAWEJwAAAACwgPAEAAAAABYQngAAAADAAsITAAAAAFhAeAIAAAAACwhPAAAAAGAB4QkAAAAALCA8AQAAAIAFhCcAAAAAsMCr4WnBggUaNGiQAgMDFRoaaumYrKws2Ww2ty09Pd2tz+nTpzVhwgQFBwcrNDRUkydPVk1NjRdmAAAAAABf8Wp4qqur07hx45Sdne3Rcenp6Tpx4oRre+WVV9z2T5gwQR9++KE2btyoNWvW6P/+7/90zz33tGTpAAAAAODGz5uDz58/X5KUn5/v0XF2u11RUVGN7tu7d6/Wr1+vXbt2acCAAZKkJUuW6Cc/+YkWL16smJiYb1QzAAAAADSmTb7ztHnzZkVGRqp3797Kzs5WZWWla9/27dsVGhrqCk6SNGzYMPn4+Oidd95pdLza2lpVV1e7bQAAAADgiTYXntLT07V8+XIVFhZq4cKF2rJli0aMGCGn0ylJqqioUGRkpNsxfn5+6tq1qyoqKhodMzc3VyEhIa4tNjbW6/MAAAAAcG3xODzNmjWrwYIOl2779u274oLGjx+vUaNGqV+/fsrIyNCaNWu0a9cubd68+YrHnD17thwOh2s7cuTIFY8FAAAAoH3y+J2nmTNnKisrq9k+PXv2vNJ6Gh0rPDxcBw8e1NChQxUVFaVTp0659blw4YJOnz7d5HtSdrtddru9xWoCAAAA0P54HJ4iIiIUERHhjVoadfToUVVWVio6OlqSlJKSoqqqKhUXFyspKUmStGnTJtXX1ys5Ofmq1QUAAACgffHqO0/l5eUqKSlReXm5nE6nSkpKVFJS4vadTAkJCVq1apUkqaamRjk5OdqxY4fKyspUWFio0aNHKz4+XmlpaZKkPn36KD09XVOmTNHOnTu1bds23XfffRo/fjwr7QEAAADwGq8uVT537lwVFBS4PicmJkqSioqKlJqaKkkqLS2Vw+GQJPn6+mr37t0qKChQVVWVYmJiNHz4cD3++ONuj9299NJLuu+++zR06FD5+Pho7Nix+v3vf+/NqQAAAABo52zGGNPaRVxt1dXVCgkJkcPhUHBwcGuXAwAAAKCVeJIN2txS5QAAAADQFhGeAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAsIDwBAAAAgAWEJwAAAACwgPAEAAAAABYQngAAAADAAsITAAAAAFhAeAIAAAAACwhPAAAAAGAB4QkAAAAALCA8AQAAAIAFhCcAAAAAsIDwBAAAAAAWEJ4AAAAAwALCEwAAAABYQHgCAAAAAAsITwAAAABgAeEJANBuOeuNai845aw3rV0KAOBbwK+1CwAAoDWcrXPq1JlzuuCsl5+vjyI7d1DHAN/WLgsA0IZx5wkA0O44641OnTmn8856dQjw1XlnvU6dOccdKABAswhPAIB250J9vS4469UxwFd+Pj7qGOCrC856Xaivb+3SAABtGOEJANDu+Pn4yM/XR2frnLpQX6+zdU75+frIz4e/FgEATfPq3xILFizQoEGDFBgYqNDQUEvHZGVlyWazuW3p6emu/WVlZZo8ebJ69Oihjh07qlevXpo3b57q6uq8NAsAwLXG18emyM4d5O/ro3N1Tvn//3eefH1srV0aAKAN8+qCEXV1dRo3bpxSUlL0wgsvWD4uPT1dy5Ytc3222+2uf9+3b5/q6+u1dOlSxcfHa8+ePZoyZYq++OILLV68uEXrBwBcuzoG+Kpbl0BdqK+Xn48PwQkAcFleDU/z58+XJOXn53t0nN1uV1RUVKP70tPT3e5E9ezZU6WlpfrjH/9IeAIAeMTXxyZfH1bYAwBY0yYf7t68ebMiIyPVu3dvZWdnq7Kystn+DodDXbt2bXJ/bW2tqqur3TYAAAAA8ESbC0/p6elavny5CgsLtXDhQm3ZskUjRoyQ0+lstP/Bgwe1ZMkS/fKXv2xyzNzcXIWEhLi22NhYb5UPAAAA4BrlcXiaNWtWgwUdLt327dt3xQWNHz9eo0aNUr9+/ZSRkaE1a9Zo165d2rx5c4O+x44dU3p6usaNG6cpU6Y0Oebs2bPlcDhc25EjR664PgAAAADtk8fvPM2cOVNZWVnN9unZs+eV1tPoWOHh4Tp48KCGDh3qaj9+/LiGDBmiQYMG6b//+7+bHcNut7stOgEAAAAAnvI4PEVERCgiIsIbtTTq6NGjqqysVHR0tKvt2LFjGjJkiJKSkrRs2TL58L0cAAAAALzMq6mjvLxcJSUlKi8vl9PpVElJiUpKSlRTU+Pqk5CQoFWrVkmSampqlJOTox07dqisrEyFhYUaPXq04uPjlZaWJumr4JSamqq4uDgtXrxYn376qSoqKlRRUeHNqQAAAABo57y6VPncuXNVUFDg+pyYmChJKioqUmpqqiSptLRUDodDkuTr66vdu3eroKBAVVVViomJ0fDhw/X444+7HrvbuHGjDh48qIMHD6pbt25u5zPGeHM6AAAAANoxm2mHiaO6ulohISFyOBwKDg5u7XIAAAAAtBJPsgEvCwEAAACABYQnAAAAALCA8AQAAAAAFhCeAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAsIDwBAAAAgAWEJwAAAACwgPAEAAAAABYQngAAAADAAsITAAAAAFhAeAIAAAAACwhPAAAAAGAB4QkAAAAALCA8AQAAAIAFhCcAAAAAsIDwBAAAAAAWEJ4AAAAAwALCEwAAAABYQHgCAAAAAAsITwAAAABgAeEJAAAAACwgPAEAAACABYQnAAAAALDAq+FpwYIFGjRokAIDAxUaGmrpmKysLNlsNrctPT290b61tbW6+eabZbPZVFJS0nKFAwAAAMAlvBqe6urqNG7cOGVnZ3t0XHp6uk6cOOHaXnnllUb7Pfzww4qJiWmJUgEAAACgWX7eHHz+/PmSpPz8fI+Os9vtioqKarbPunXrtGHDBr322mtat27dlZYIAAAAAJa0yXeeNm/erMjISPXu3VvZ2dmqrKx023/y5ElNmTJFL774ogIDAy87Xm1traqrq902AAAAAPBEmwtP6enpWr58uQoLC7Vw4UJt2bJFI0aMkNPplCQZY5SVlaWpU6dqwIABlsbMzc1VSEiIa4uNjfXmFAAAAABcgzwOT7NmzWqwoMOl2759+664oPHjx2vUqFHq16+fMjIytGbNGu3atUubN2+WJC1ZskRnzpzR7NmzLY85e/ZsORwO13bkyJErrg8AAABA++TxO08zZ85UVlZWs3169ux5pfU0OlZ4eLgOHjyooUOHatOmTdq+fbvsdrtbvwEDBmjChAkqKChoMIbdbm/QHwAAAAA84XF4ioiIUEREhDdqadTRo0dVWVmp6OhoSdLvf/97PfHEE679x48fV1pamlasWKHk5OSrVhcAAACA9sWrq+2Vl5fr9OnTKi8vl9PpdH0XU3x8vIKCgiRJCQkJys3N1ZgxY1RTU6P58+dr7NixioqK0qFDh/Twww8rPj5eaWlpkqS4uDi3c1wcp1evXurWrZs3pwMAAACgHfNqeJo7d67bY3SJiYmSpKKiIqWmpkqSSktL5XA4JEm+vr7avXu3CgoKVFVVpZiYGA0fPlyPP/44j90BAAAAaFU2Y4xp7SKuturqaoWEhMjhcCg4OLi1ywEAAADQSjzJBm1uqXIAAAAAaIsITwAAAABgAeEJAAAAACwgPAEAAACABYQnAAAAALCA8AQAAAAAFhCeAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAsIDwBAAAAgAWEJwAAAACwgPAEAAAAABYQngAAAADAAsITAAAAAFhAeAIAAAAACwhPAAAAAGAB4QkAAAAALCA8AQAAAIAFhCcAAAAAsIDwBAAAAAAWEJ4AAAAAwALCEwAAAABYQHgCAAAAAAsITwAAAABggdfC04IFCzRo0CAFBgYqNDTU0jFZWVmy2WxuW3p6eoN+a9euVXJysjp27KguXbooIyOjZYsHAAAAgEv4eWvguro6jRs3TikpKXrhhRcsH5eenq5ly5a5Ptvtdrf9r732mqZMmaInn3xSt912my5cuKA9e/a0WN0AAAAA0Bivhaf58+dLkvLz8z06zm63KyoqqtF9Fy5c0AMPPKBFixZp8uTJrvYbb7zxiusEAAAAACva3DtPmzdvVmRkpHr37q3s7GxVVla69r333ns6duyYfHx8lJiYqOjoaI0YMeKyd55qa2tVXV3ttgEAAACAJ9pUeEpPT9fy5ctVWFiohQsXasuWLRoxYoScTqck6eOPP5YkPfroo3rkkUe0Zs0adenSRampqTp9+nST4+bm5iokJMS1xcbGXpX5AAAAALh2eBSeZs2a1WBBh0u3ffv2XXEx48eP16hRo9SvXz9lZGRozZo12rVrlzZv3ixJqq+vlyTNmTNHY8eOVVJSkpYtWyabzaaVK1c2Oe7s2bPlcDhc25EjR664RgAAAADtk0fvPM2cOVNZWVnN9unZs+c3qafBWOHh4Tp48KCGDh2q6OhoSe7vONntdvXs2VPl5eVNjmO32xssPAEAAAAAnvAoPEVERCgiIsJbtTRw9OhRVVZWukJTUlKS7Ha7SktLNXjwYEnS+fPnVVZWpu7du1+1ugAAAAC0P15756m8vFwlJSUqLy+X0+lUSUmJSkpKVFNT4+qTkJCgVatWSZJqamqUk5OjHTt2qKysTIWFhRo9erTi4+OVlpYmSQoODtbUqVM1b948bdiwQaWlpcrOzpYkjRs3zltTAQAAAADvLVU+d+5cFRQUuD4nJiZKkoqKipSamipJKi0tlcPhkCT5+vpq9+7dKigoUFVVlWJiYjR8+HA9/vjjbo/cLVq0SH5+fsrMzNTZs2eVnJysTZs2qUuXLt6aCgAAAADIZowxrV3E1VZdXa2QkBA5HA4FBwe3djkAAAAAWokn2aBNLVUOAAAAAG0V4QkAAAAALCA8AQAAAIAFhCcAAAAAsIDwBAAAAAAWEJ4AAAAAwALCEwAAAABYQHgCAAAAAAsITwAAAABgAeEJAAAAACwgPAEAAACABYQnAAAAALCA8AQAAAAAFhCeAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAsIDwBAAAAgAWEJwAAAACwgPAEAAAAABYQngAAAADAAsITAAAAAFhAeAIAAAAACwhPAAAAAGAB4QkAAAAALPBaeFqwYIEGDRqkwMBAhYaGWjomKytLNpvNbUtPT3frs3//fo0ePVrh4eEKDg7W4MGDVVRU5IUZAAAAAMC/eC081dXVady4ccrOzvbouPT0dJ04ccK1vfLKK277b7/9dl24cEGbNm1ScXGx+vfvr9tvv10VFRUtWT4AAAAAuPHz1sDz58+XJOXn53t0nN1uV1RUVKP7PvvsMx04cEAvvPCCbrrpJknSU089peeee0579uxp8jgAAAAA+Kba3DtPmzdvVmRkpHr37q3s7GxVVla69oWFhal3795avny5vvjiC124cEFLly5VZGSkkpKSmhyztrZW1dXVbhsAAAAAeMJrd56uRHp6un7605+qR48eOnTokH7zm99oxIgR2r59u3x9fWWz2fTWW28pIyNDnTt3lo+PjyIjI7V+/Xp16dKlyXFzc3Ndd8IAAAAA4Ep4dOdp1qxZDRZ0uHTbt2/fFRczfvx4jRo1Sv369VNGRobWrFmjXbt2afPmzZIkY4ymTZumyMhIbd26VTt37lRGRobuuOMOnThxoslxZ8+eLYfD4dqOHDlyxTUCAAAAaJ88uvM0c+ZMZWVlNdunZ8+e36SeBmOFh4fr4MGDGjp0qDZt2qQ1a9bo888/V3BwsCTpueee08aNG1VQUKBZs2Y1Oo7dbpfdbm+xugAAAAC0Px6Fp4iICEVERHirlgaOHj2qyspKRUdHS5K+/PJLSZKPj/sNMx8fH9XX11+1ugAAAAC0P15bMKK8vFwlJSUqLy+X0+lUSUmJSkpKVFNT4+qTkJCgVatWSZJqamqUk5OjHTt2qKysTIWFhRo9erTi4+OVlpYmSUpJSVGXLl00ceJEvf/++9q/f79ycnJ0+PBhjRw50ltTAQAAAADvLRgxd+5cFRQUuD4nJiZKkoqKipSamipJKi0tlcPhkCT5+vpq9+7dKigoUFVVlWJiYjR8+HA9/vjjrkfuwsPDtX79es2ZM0e33Xabzp8/r759++r1119X//79vTUVAAAAAJDNGGNau4irrbq6WiEhIXI4HK53pwAAAAC0P55kgzb3PU8AAAAA0BYRngAAAADAAsITAAAAAFhAeAIAAAAACwhPAAAAAGAB4QkAAAAALCA8AQAAAIAFhCcAAAAAsIDwBAAAAAAWEJ4AAAAAwALCEwAAAABYQHgCAAAAAAsITwAAAABgAeEJAAAAACwgPAEAAACABYQnAAAAALCA8AQAAAAAFhCeAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAsIDwBAAAAgAWEJwAAAACwgPAEAAAAABYQngAAAADAAq+FpwULFmjQoEEKDAxUaGio5eP27t2rUaNGKSQkRJ06ddIPfvADlZeXu/afO3dO06ZNU1hYmIKCgjR27FidPHnSCzMAAAAAgH/xWniqq6vTuHHjlJ2dbfmYQ4cOafDgwUpISNDmzZu1e/du/fa3v1WHDh1cfR588EG98cYbWrlypbZs2aLjx4/rpz/9qTemAAAAAAAuNmOM8eYJ8vPzNWPGDFVVVV227/jx4+Xv768XX3yx0f0Oh0MRERF6+eWX9bOf/UyStG/fPvXp00fbt2/XD3/4Q0s1VVdXKyQkRA6HQ8HBwZbnAgAAAODa4kk28LtKNV1WfX291q5dq4cfflhpaWn65z//qR49emj27NnKyMiQJBUXF+v8+fMaNmyY67iEhATFxcU1G55qa2tVW1vr+uxwOCR99YMCAAAA0H5dzARW7im1mfB06tQp1dTU6KmnntITTzyhhQsXav369frpT3+qoqIi3XrrraqoqFBAQECDd6iuu+46VVRUNDl2bm6u5s+f36A9Nja2pacBAAAA4FvozJkzCgkJabaPR+Fp1qxZWrhwYbN99u7dq4SEBE+GlfTVnSdJGj16tB588EFJ0s0336x//OMf+tOf/qRbb73V4zEvmj17th566CG3c50+fVphYWGy2WxXPC68q7q6WrGxsTpy5AiPV8ISrhl4imsGnuKagae4Zto+Y4zOnDmjmJiYy/b1KDzNnDlTWVlZzfbp2bOnJ0O6hIeHy8/PTzfeeKNbe58+ffT2229LkqKiolRXV6eqqiq3u08nT55UVFRUk2Pb7XbZ7Xa3Nk9WAETrCg4O5pcNPMI1A09xzcBTXDPwFNdM23a5O04XeRSeIiIiFBERcUUFXU5AQIB+8IMfqLS01K19//796t69uyQpKSlJ/v7+Kiws1NixYyVJpaWlKi8vV0pKilfqAgAAAADJi+88lZeX6/Tp0yovL5fT6VRJSYkkKT4+XkFBQZK+WuwhNzdXY8aMkSTl5OTo3//933XLLbdoyJAhWr9+vd544w1t3rxZ0leJcPLkyXrooYfUtWtXBQcH6/7771dKSorllfYAAAAA4Ep4LTzNnTtXBQUFrs+JiYmSpKKiIqWmpkr66q7RxZXvJGnMmDH605/+pNzcXE2fPl29e/fWa6+9psGDB7v6PPPMM/Lx8dHYsWNVW1urtLQ0Pffcc96aBlqR3W7XvHnzGjxyCTSFawae4pqBp7hm4CmumWuL17/nCQAAAACuBT6tXQAAAAAAfBsQngAAAADAAsITAAAAAFhAeAIAAAAACwhPaDWnT5/WhAkTFBwcrNDQUE2ePFk1NTXNHnPu3DlNmzZNYWFhCgoK0tixY3Xy5MlG+1ZWVqpbt26y2WyqqqrywgxwtXnjmnn//fd11113KTY2Vh07dlSfPn307LPPensq8JL/+q//0vXXX68OHTooOTlZO3fubLb/ypUrlZCQoA4dOqhfv376+9//7rbfGKO5c+cqOjpaHTt21LBhw3TgwAFvTgFXWUteM+fPn9evf/1r9evXT506dVJMTIx+8Ytf6Pjx496eBq6ilv4983VTp06VzWZTXl5eC1eNFmOAVpKenm769+9vduzYYbZu3Wri4+PNXXfd1ewxU6dONbGxsaawsNC8++675oc//KEZNGhQo31Hjx5tRowYYSSZzz//3AszwNXmjWvmhRdeMNOnTzebN282hw4dMi+++KLp2LGjWbJkibengxb217/+1QQEBJg///nP5sMPPzRTpkwxoaGh5uTJk43237Ztm/H19TVPP/20+eijj8wjjzxi/P39zQcffODq89RTT5mQkBCzevVq8/7775tRo0aZHj16mLNnz16tacGLWvqaqaqqMsOGDTMrVqww+/btM9u3bzcDBw40SUlJV3Na8CJv/J656H//939N//79TUxMjHnmmWe8PBNcKcITWsVHH31kJJldu3a52tatW2dsNps5duxYo8dUVVUZf39/s3LlSlfb3r17jSSzfft2t77PPfecufXWW01hYSHh6Rrh7Wvm6+69914zZMiQliseV8XAgQPNtGnTXJ+dTqeJiYkxubm5jfa/8847zciRI93akpOTzS9/+UtjjDH19fUmKirKLFq0yLW/qqrK2O1288orr3hhBrjaWvqaaczOnTuNJPPJJ5+0TNFoVd66Zo4ePWq+853vmD179pju3bsTntowHttDq9i+fbtCQ0M1YMAAV9uwYcPk4+Ojd955p9FjiouLdf78eQ0bNszVlpCQoLi4OG3fvt3V9tFHH+mxxx7T8uXL5ePDJX6t8OY1cymHw6GuXbu2XPHwurq6OhUXF7v9Wfv4+GjYsGFN/llv377drb8kpaWlufofPnxYFRUVbn1CQkKUnJzc7PWDbwdvXDONcTgcstlsCg0NbZG60Xq8dc3U19crMzNTOTk56tu3r3eKR4vhvyzRKioqKhQZGenW5ufnp65du6qioqLJYwICAhr8BXTddde5jqmtrdVdd92lRYsWKS4uziu1o3V465q51D/+8Q+tWLFC99xzT4vUjavjs88+k9Pp1HXXXefW3tyfdUVFRbP9L/7TkzHx7eGNa+ZS586d069//WvdddddCg4ObpnC0Wq8dc0sXLhQfn5+mj59essXjRZHeEKLmjVrlmw2W7Pbvn37vHb+2bNnq0+fPvr5z3/utXOgZbX2NfN1e/bs0ejRozVv3jwNHz78qpwTwLXp/PnzuvPOO2WM0R//+MfWLgdtVHFxsZ599lnl5+fLZrO1djmwwK+1C8C1ZebMmcrKymq2T8+ePRUVFaVTp065tV+4cEGnT59WVFRUo8dFRUWprq5OVVVVbncSTp486Tpm06ZN+uCDD/S3v/1N0lcrZUlSeHi45syZo/nz51/hzOAtrX3NXPTRRx9p6NChuueee/TII49c0VzQesLDw+Xr69tg9c3G/qwvioqKarb/xX+ePHlS0dHRbn1uvvnmFqwercEb18xFF4PTJ598ok2bNnHX6RrhjWtm69atOnXqlNvTMk6nUzNnzlReXp7KyspadhL4xrjzhBYVERGhhISEZreAgAClpKSoqqpKxcXFrmM3bdqk+vp6JScnNzp2UlKS/P39VVhY6GorLS1VeXm5UlJSJEmvvfaa3n//fZWUlKikpETPP/+8pK9+OU2bNs2LM8eVau1rRpI+/PBDDRkyRBMnTtSCBQu8N1l4TUBAgJKSktz+rOvr61VYWOj2Z/11KSkpbv0laePGja7+PXr0UFRUlFuf6upqvfPOO02OiW8Pb1wz0r+C04EDB/TWW28pLCzMOxPAVeeNayYzM1O7d+92/XdLSUmJYmJilJOTozfffNN7k8GVa+0VK9B+paenm8TERPPOO++Yt99+29xwww1uy04fPXrU9O7d27zzzjuutqlTp5q4uDizadMm8+6775qUlBSTkpLS5DmKiopYbe8a4o1r5oMPPjARERHm5z//uTlx4oRrO3Xq1FWdG765v/71r8Zut5v8/Hzz0UcfmXvuuceEhoaaiooKY4wxmZmZZtasWa7+27ZtM35+fmbx4sVm7969Zt68eY0uVR4aGmpef/11s3v3bjN69GiWKr+GtPQ1U1dXZ0aNGmW6detmSkpK3H6n1NbWtsoc0bK88XvmUqy217YRntBqKisrzV133WWCgoJMcHCwmTRpkjlz5oxr/+HDh40kU1RU5Go7e/asuffee02XLl1MYGCgGTNmjDlx4kST5yA8XVu8cc3MmzfPSGqwde/e/SrODC1lyZIlJi4uzgQEBJiBAweaHTt2uPbdeuutZuLEiW79X331VfPd737XBAQEmL59+5q1a9e67a+vrze//e1vzXXXXWfsdrsZOnSoKS0tvRpTwVXSktfMxd9BjW1f/72Eb7eW/j1zKcJT22Yz5v+/FAIAAAAAaBLvPAEAAACABYQnAAAAALCA8AQAAAAAFhCeAAAAAMACwhMAAAAAWEB4AgAAAAALCE8AAAAAYAHhCQAAAAAsIDwBAAAAgAWEJwAAAACwgPAEAAAAABYQngAAAADAgv8HCEflyWwecr4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filename must end in `.weights.h5`. Received: filepath=train_log/0000",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-819888735.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mvisualize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mexport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_log/%04d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r step: %d, log10(loss): %.3f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10-2539483379.py\u001b[0m in \u001b[0;36mexport_model\u001b[0;34m(ca, base_fn)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   cf = ca.call.get_concrete_function(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;34m\"The filename must end in `.weights.h5`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;34mf\"Received: filepath={filepath}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=train_log/0000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAscSKkRaFwp"
      },
      "source": [
        "# Figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqvkfl9W4ODI"
      },
      "source": [
        "#@title Training Progress (Checkpoints)\n",
        "\n",
        "models = []\n",
        "for i in [100, 500, 1000, 4000]:\n",
        "  ca = CAModel()\n",
        "  ca.load_weights('train_log/%04d'%i)\n",
        "  models.append(ca)\n",
        "\n",
        "out_fn = 'train_steps_damage_%d.mp4'%DAMAGE_N\n",
        "x = np.zeros([len(models), 72, 72, CHANNEL_N], np.float32)\n",
        "x[..., 36, 36, 3:] = 1.0\n",
        "with VideoWriter(out_fn) as vid:\n",
        "  for i in tqdm.trange(500):\n",
        "    vis = np.hstack(to_rgb(x))\n",
        "    vid.add(zoom(vis, 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "mvp.ipython_display(out_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeXZKb5v2gxj"
      },
      "source": [
        "#@title Training Progress (Batches)\n",
        "frames = sorted(glob.glob('train_log/batches_*.jpg'))\n",
        "mvp.ImageSequenceClip(frames, fps=10.0).write_videofile('batches.mp4')\n",
        "mvp.ipython_display('batches.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4JAbAJf6Alw"
      },
      "source": [
        "#@title Pool Contents\n",
        "frames = sorted(glob.glob('train_log/*_pool.jpg'))[:80]\n",
        "mvp.ImageSequenceClip(frames, fps=20.0).write_videofile('pool.mp4')\n",
        "mvp.ipython_display('pool.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyxeGm6dJX8D"
      },
      "source": [
        "## Pretrained Models and Figures\n",
        "\n",
        "Please run the cell below to download pretrained models that are used to generate the subsequent figures. The figures generated after this are generated using the pretrained CAs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiGl7S0E6-OA"
      },
      "source": [
        "!wget -O models.zip 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/models.zip?raw=true'\n",
        "!unzip -oq models.zip\n",
        "\n",
        "EMOJI = '🦎😀💥👁🐠🦋🐞🕸🥨🎄'\n",
        "\n",
        "def get_model(emoji='🦋', fire_rate=0.5, use_pool=1, damage_n=3, run=0,\n",
        "              prefix='models/', output='model'):\n",
        "  path = prefix\n",
        "  assert fire_rate in [0.5, 1.0]\n",
        "  if fire_rate==0.5:\n",
        "    path += 'use_sample_pool_%d damage_n_%d '%(use_pool, damage_n)\n",
        "  elif fire_rate==1.0:\n",
        "    path += 'fire_rate_1.0 '\n",
        "  code = hex(ord(emoji))[2:].upper()\n",
        "  path += 'target_emoji_%s run_index_%d/08000'%(code, run)\n",
        "  assert output in ['model', 'json']\n",
        "  if output == 'model':\n",
        "    ca = CAModel(channel_n=16, fire_rate=fire_rate)\n",
        "    ca.load_weights(path)\n",
        "    return ca\n",
        "  elif output == 'json':\n",
        "    return open(path+'.json', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyMms2wKwX9x"
      },
      "source": [
        "atlas = np.hstack([load_emoji(e) for e in EMOJI])\n",
        "imshow(atlas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqgtL5VpLEeL"
      },
      "source": [
        "#@title Teaser\n",
        "models = [get_model(emoji, run=1) for emoji in EMOJI]\n",
        "\n",
        "with VideoWriter('teaser.mp4') as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  # grow\n",
        "  for i in tqdm.trange(200):\n",
        "    k = i//20\n",
        "    if i%20==0 and k<len(EMOJI):\n",
        "      x[k, 32, 32, 3:] = 1.0\n",
        "    vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # damage\n",
        "  mask = PIL.Image.new('L', (64*5, 64*2))\n",
        "  draw = PIL.ImageDraw.Draw(mask)\n",
        "  for i in tqdm.trange(400):\n",
        "    cx, r = i*3-20, 6\n",
        "    y1, y2 = 32+np.sin(i/5+np.pi)*8, 32+64+np.sin(i/5)*8\n",
        "    draw.rectangle((0, 0, 64*5, 64*2), fill=0)\n",
        "    draw.ellipse((cx-r, y1-r, cx+r, y1+r), fill=255)\n",
        "    draw.ellipse((cx-r, y2-r, cx+r, y2+r), fill=255)\n",
        "    x *= 1.0-(np.float32(mask).reshape(2, 64, 5, 64)\n",
        "        .transpose([0, 2, 1, 3]).reshape(10, 64, 64, 1))/255.0\n",
        "    if i<200 or i%2 == 0:\n",
        "      vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  last = zoom(tile2d(to_rgb(x), 5), 2)\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(last*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display('teaser.mp4', loop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O4tzfe-GRJ7"
      },
      "source": [
        "#@title Unstable Patterns\n",
        "!wget -O slider.png 'https://github.com/google-research/self-organising-systems/raw/master/assets/growing_ca/slider.png?raw=true'\n",
        "\n",
        "import PIL.ImageFont\n",
        "from matplotlib import font_manager as fm\n",
        "font_fn = fm.findfont(fm.FontProperties())\n",
        "font = PIL.ImageFont.truetype(font_fn, 20)\n",
        "\n",
        "models = [get_model(ch, use_pool=0, damage_n=0) for ch in EMOJI]\n",
        "fn = 'unstable.mp4'\n",
        "with VideoWriter(fn) as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  x[:, 32, 32, 3:] = 1.0\n",
        "  # grow\n",
        "  slider = PIL.Image.open(\"slider.png\")\n",
        "  for i in tqdm.trange(1000):\n",
        "    if i<200 or i%5 == 0:\n",
        "      vis = zoom(tile2d(to_rgb(x), 5), 4).clip(0, 1)\n",
        "      vis_extended = np.concatenate((vis, np.ones((164, vis.shape[1], 3))), axis=0)\n",
        "      im = np.uint8(vis_extended*255)\n",
        "      im = PIL.Image.fromarray(im)\n",
        "      im.paste(slider, box=(20, vis.shape[0]+20))\n",
        "      draw = PIL.ImageDraw.Draw(im)\n",
        "      p_x = (14 + (610/1000)*i)*2.0\n",
        "      draw.rectangle([p_x, vis.shape[0]+20+55, p_x+10, vis.shape[0]+20+82], fill=\"#434343bd\")\n",
        "      vid.add(np.uint8(im))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(vis_extended*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display(fn, loop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CVR9MeYnjuY"
      },
      "source": [
        "#@title Rotation\n",
        "row_size = 4\n",
        "models_of_interest = [\"🦋\",\"🦎\",\"🐠\",\"😀\"]\n",
        "num_images = 16\n",
        "imgs = []\n",
        "start_angle = np.random.randint(13, 76)\n",
        "\n",
        "for i in np.arange(num_images):\n",
        "  ang = start_angle + i * np.random.randint(36, 111)\n",
        "  ang = ang/360.0 * 2 * np.pi\n",
        "  if i % row_size == 0:\n",
        "    ca = get_model(models_of_interest[i // row_size])\n",
        "  x = np.zeros([1, 56, 56, CHANNEL_N], np.float32)\n",
        "  x[:, 28, 28, 3:] = 1.0\n",
        "  for i in range(500):\n",
        "    ang = tf.constant(ang, tf.float32)\n",
        "    x = ca(x, angle=ang)\n",
        "  imgs.append(to_rgb(x)[0])\n",
        "# Assumes the result is a multiple of row_size\n",
        "assert len(imgs) % row_size == 0\n",
        "imgs = zip(*(iter(imgs),) * row_size)\n",
        "\n",
        "imgs_arr = np.concatenate([np.hstack(im_row) for im_row in imgs])\n",
        "vis = zoom(imgs_arr, 4)\n",
        "\n",
        "imshow(vis, fmt='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5JRLGxX1dnX"
      },
      "source": [
        "#@title Regeneration (trained without damage)\n",
        "models = [get_model(ch, damage_n=0) for ch in '😀🦋🦎']\n",
        "with VideoWriter('regen1.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i < 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen1.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDzJM69u4_8p"
      },
      "source": [
        "#@title Regeneration (trained with damage)\n",
        "models = [get_model(ch, damage_n=3) for ch in '😀🦋🦎']\n",
        "with VideoWriter('regen2.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i < 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen2.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ1u2MqFy7Ni"
      },
      "source": [
        "#@title Planarian\n",
        "!wget -O planarian.zip 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/planarian.zip?raw=true'\n",
        "!unzip -oq planarian.zip -d planarian\n",
        "\n",
        "ca = CAModel()\n",
        "ca.load_weights('planarian/train_log/8000')\n",
        "\n",
        "x = np.zeros([1, 64, 96, CHANNEL_N], np.float32)\n",
        "x[:, 32, 48, 3:] = 1.0\n",
        "with VideoWriter('planarian.mp4', 30.0) as vid:\n",
        "  for i in range(400):\n",
        "    vid.add(zoom(to_rgb(x[0])))\n",
        "    x = ca(x, angle=np.pi/2.0)\n",
        "    if i==150:\n",
        "      x = x.numpy()\n",
        "      for k in range(24):\n",
        "        x[:,:24] = np.roll(x[:,:24], 1, 2)\n",
        "        x[:,-24:] = np.roll(x[:,-24:], -1, 2)\n",
        "        vid.add(zoom(to_rgb(x[0])))\n",
        "      for k in range(20):\n",
        "        vid.add(zoom(to_rgb(x[0])))\n",
        "\n",
        "mvp.ipython_display('planarian.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M-oDuhea7bR"
      },
      "source": [
        "# Interactive Demos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7ypa-b7_fTn"
      },
      "source": [
        "#@title TensorFlow.js Demo {run:\"auto\", vertical-output: true}\n",
        "#@markdown Select \"CHECKPOINT\" model to load the checkpoint created by running cells from the \"Training\" section of this notebook\n",
        "import IPython.display\n",
        "\n",
        "model = \"CHECKPOINT\"  #@param ['CHECKPOINT', '😀 1F600', '💥 1F4A5', '👁 1F441', '🦎 1F98E', '🐠 1F420', '🦋 1F98B', '🐞 1F41E', '🕸 1F578', '🥨 1F968', '🎄 1F384']\n",
        "model_type = '3 regenerating'  #@param ['1 naive', '2 persistent', '3 regenerating']\n",
        "\n",
        "#@markdown Shift-click to seed the pattern\n",
        "\n",
        "if model != 'CHECKPOINT':\n",
        "  code = model.split(' ')[1]\n",
        "  emoji = chr(int(code, 16))\n",
        "  experiment_i = int(model_type.split()[0])-1\n",
        "  use_pool = (0, 1, 1)[experiment_i]\n",
        "  damage_n = (0, 0, 3)[experiment_i]\n",
        "  model_str = get_model(emoji, use_pool=use_pool, damage_n=damage_n, output='json')\n",
        "else:\n",
        "  last_checkpoint_fn = sorted(glob.glob('train_log/*.json'))[-1]\n",
        "  model_str = open(last_checkpoint_fn).read()\n",
        "\n",
        "data_js = '''\n",
        "  window.GRAPH_URL = URL.createObjectURL(new Blob([`%s`], {type: 'application/json'}));\n",
        "'''%(model_str)\n",
        "\n",
        "display(IPython.display.Javascript(data_js))\n",
        "\n",
        "\n",
        "IPython.display.HTML('''\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.3.0/dist/tf.min.js\"></script>\n",
        "\n",
        "<canvas id='canvas' style=\"border: 1px solid black; image-rendering: pixelated;\"></canvas>\n",
        "\n",
        "<script>\n",
        "  \"use strict\";\n",
        "\n",
        "  const sleep = (ms)=>new Promise(resolve => setTimeout(resolve, ms));\n",
        "\n",
        "  const parseConsts = model_graph=>{\n",
        "    const dtypes = {'DT_INT32':['int32', 'intVal', Int32Array],\n",
        "                    'DT_FLOAT':['float32', 'floatVal', Float32Array]};\n",
        "\n",
        "    const consts = {};\n",
        "    model_graph.modelTopology.node.filter(n=>n.op=='Const').forEach((node=>{\n",
        "      const v = node.attr.value.tensor;\n",
        "      const [dtype, field, arrayType] = dtypes[v.dtype];\n",
        "      if (!v.tensorShape.dim) {\n",
        "        consts[node.name] = [tf.scalar(v[field][0], dtype)];\n",
        "      } else {\n",
        "        // if there is a 0-length dimension, the exported graph json lacks \"size\"\n",
        "        const shape = v.tensorShape.dim.map(d=>(!d.size) ? 0 : parseInt(d.size));\n",
        "        let arr;\n",
        "        if (v.tensorContent) {\n",
        "          const data = atob(v.tensorContent);\n",
        "          const buf = new Uint8Array(data.length);\n",
        "          for (var i=0; i<data.length; ++i) {\n",
        "            buf[i] = data.charCodeAt(i);\n",
        "          }\n",
        "          arr = new arrayType(buf.buffer);\n",
        "        } else {\n",
        "          const size = shape.reduce((a, b)=>a*b);\n",
        "          arr = new arrayType(size);\n",
        "          if (size) {\n",
        "            arr.fill(v[field][0]);\n",
        "          }\n",
        "        }\n",
        "        consts[node.name] = [tf.tensor(arr, shape, dtype)];\n",
        "      }\n",
        "    }));\n",
        "    return consts;\n",
        "  }\n",
        "\n",
        "  const run = async ()=>{\n",
        "    const r = await fetch(GRAPH_URL);\n",
        "    const consts = parseConsts(await r.json());\n",
        "\n",
        "    const model = await tf.loadGraphModel(GRAPH_URL);\n",
        "    Object.assign(model.weights, consts);\n",
        "\n",
        "    let seed = new Array(16).fill(0).map((x, i)=>i<3?0:1);\n",
        "    seed = tf.tensor(seed, [1, 1, 1, 16]);\n",
        "\n",
        "    const D = 96;\n",
        "    const initState = tf.tidy(()=>{\n",
        "      const D2 = D/2;\n",
        "      const a = seed.pad([[0, 0], [D2-1, D2], [D2-1, D2], [0,0]]);\n",
        "      return a;\n",
        "    });\n",
        "\n",
        "    const state = tf.variable(initState);\n",
        "    const [_, h, w, ch] = state.shape;\n",
        "\n",
        "    const damage = (x, y, r)=>{\n",
        "      tf.tidy(()=>{\n",
        "        const rx = tf.range(0, w).sub(x).div(r).square().expandDims(0);\n",
        "        const ry = tf.range(0, h).sub(y).div(r).square().expandDims(1);\n",
        "        const mask = rx.add(ry).greater(1.0).expandDims(2);\n",
        "        state.assign(state.mul(mask));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    const plantSeed = (x, y)=>{\n",
        "      const x2 = w-x-seed.shape[2];\n",
        "      const y2 = h-y-seed.shape[1];\n",
        "      if (x<0 || x2<0 || y2<0 || y2<0)\n",
        "        return;\n",
        "      tf.tidy(()=>{\n",
        "        const a = seed.pad([[0, 0], [y, y2], [x, x2], [0,0]]);\n",
        "        state.assign(state.add(a));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    const scale = 4;\n",
        "\n",
        "    const canvas = document.getElementById('canvas');\n",
        "    const ctx = canvas.getContext('2d');\n",
        "    canvas.width = w;\n",
        "    canvas.height = h;\n",
        "    canvas.style.width = `${w*scale}px`;\n",
        "    canvas.style.height = `${h*scale}px`;\n",
        "\n",
        "    canvas.onmousedown = e=>{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "        const y = Math.floor(e.clientY/scale);\n",
        "        if (e.buttons == 1) {\n",
        "          if (e.shiftKey) {\n",
        "            plantSeed(x, y);\n",
        "          } else {\n",
        "            damage(x, y, 8);\n",
        "          }\n",
        "        }\n",
        "    }\n",
        "    canvas.onmousemove = e=>{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "      const y = Math.floor(e.clientY/scale);\n",
        "      if (e.buttons == 1 && !e.shiftKey) {\n",
        "        damage(x, y, 8);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    function step() {\n",
        "      tf.tidy(()=>{\n",
        "        state.assign(model.execute(\n",
        "            {x:state, fire_rate:tf.tensor(0.5),\n",
        "            angle:tf.tensor(0.0), step_size:tf.tensor(1.0)}, ['Identity']));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    function render() {\n",
        "      step();\n",
        "\n",
        "      const imageData = tf.tidy(()=>{\n",
        "        const rgba = state.slice([0, 0, 0, 0], [-1, -1, -1, 4]);\n",
        "        const a = state.slice([0, 0, 0, 3], [-1, -1, -1, 1]);\n",
        "        const img = tf.tensor(1.0).sub(a).add(rgba).mul(255);\n",
        "        const rgbaBytes = new Uint8ClampedArray(img.dataSync());\n",
        "        return new ImageData(rgbaBytes, w, h);\n",
        "      });\n",
        "      ctx.putImageData(imageData, 0, 0);\n",
        "\n",
        "      requestAnimationFrame(render);\n",
        "    }\n",
        "    render();\n",
        "  }\n",
        "  run();\n",
        "\n",
        "</script>\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POma99rMIfV4"
      },
      "source": [
        "#@title WebGL Demo\n",
        "\n",
        "#@markdown This code exports quantized models for the WebGL demo that is used in the article.\n",
        "#@markdown The demo code can be found at https://github.com/distillpub/post--growing-ca/blob/master/public/ca.js\n",
        "\n",
        "def pack_layer(weight, bias, outputType=np.uint8):\n",
        "  in_ch, out_ch = weight.shape\n",
        "  assert (in_ch%4==0) and (out_ch%4==0) and (bias.shape==(out_ch,))\n",
        "  weight_scale, bias_scale = 1.0, 1.0\n",
        "  if outputType == np.uint8:\n",
        "    weight_scale = 2.0*np.abs(weight).max()\n",
        "    bias_scale = 2.0*np.abs(bias).max()\n",
        "    weight = np.round((weight/weight_scale+0.5)*255)\n",
        "    bias = np.round((bias/bias_scale+0.5)*255)\n",
        "  packed = np.vstack([weight, bias[None,...]])\n",
        "  packed = packed.reshape(in_ch+1, out_ch//4, 4)\n",
        "  packed = outputType(packed)\n",
        "  packed_b64 = base64.b64encode(packed.tobytes()).decode('ascii')\n",
        "  return {'data_b64': packed_b64, 'in_ch': in_ch, 'out_ch': out_ch,\n",
        "          'weight_scale': weight_scale, 'bias_scale': bias_scale,\n",
        "          'type': outputType.__name__}\n",
        "\n",
        "def export_ca_to_webgl_demo(ca, outputType=np.uint8):\n",
        "  # reorder the first layer inputs to meet webgl demo perception layout\n",
        "  chn = ca.channel_n\n",
        "  w1 = ca.weights[0][0, 0].numpy()\n",
        "  w1 = w1.reshape(chn, 3, -1).transpose(1, 0, 2).reshape(3*chn, -1)\n",
        "  layers = [\n",
        "      pack_layer(w1, ca.weights[1].numpy(), outputType),\n",
        "      pack_layer(ca.weights[2][0, 0].numpy(), ca.weights[3].numpy(), outputType)\n",
        "  ]\n",
        "  return json.dumps(layers)\n",
        "\n",
        "with zipfile.ZipFile('webgl_models8.zip', 'w') as zf:\n",
        "  for e in EMOJI:\n",
        "    zf.writestr('ex1_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=0, damage_n=0)))\n",
        "    run = 1 if e in '😀🕸' else 0  # select runs that happen to quantize better\n",
        "    zf.writestr('ex2_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=0, run=run)))\n",
        "    run = 1 if e in '🦎' else 0    # select runs that happen to quantize better\n",
        "    zf.writestr('ex3_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=3, run=run)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}